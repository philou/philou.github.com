<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ruby | Philippe Bourgau's blog]]></title>
  <link href="http://philippe.bourgau.net/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://philippe.bourgau.net/"/>
  <updated>2017-01-19T05:03:43+00:00</updated>
  <id>http://philippe.bourgau.net/</id>
  <author>
    <name><![CDATA[Philippe Bourgau]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Verify the Big O Complexity of Ruby Code in RSpec]]></title>
    <link href="http://philippe.bourgau.net/verify-the-big-o-complexity-of-ruby-code-in-rspec/"/>
    <updated>2017-01-04T17:48:00+00:00</updated>
    <id>http://philippe.bourgau.net/verify-the-big-o-complexity-of-ruby-code-in-rspec</id>
    <content type="html"><![CDATA[<p>It might be possible to discover performance regressions before running your long and large scale benchmarks !</p>

<p><a href="https://github.com/philou/complexity-assert">complexity_assert</a> is an <a href="http://rspec.info/">RSpec</a> library that determines and checks the <a href="http://bigocheatsheet.com/">big O complexity</a> of a piece of code. Once you&rsquo;ve determined the performance critical sections of your system, you can use it to verify that they perform with the complexity you expect.</p>

<h2>How does it work ?</h2>

<p>The gem itself is the result of an experiment to learn machine learning in 20 hours (you can read more about that experiment in <a href="/how-i-got-my-feet-wet-with-machine-learning-with-the-first-20-hours/">my previous post</a> if you want).</p>

<p>Suppose you have some a method, let&rsquo;s call it <code>match_products_with_orders(products, orders)</code> which is called in in one of your processes with very large arguments. Badly written, this method could be quadratic (O(n²)), which would lead to catastrophic performances in production. When coding it, you&rsquo;ve taken particular care to make it perform in linear time. Unfortunately, it could easily slip back to a slower implementation with a bad refactoring &hellip; Using complexity_assert, you can make sure that this does not happen :</p>

<p>``` ruby</p>

<h1>An adapter class to fit the code to measure in complexity assert</h1>

<p>class ProductsOrdersMatching</p>

<pre><code># Generate some arguments of a particular size
def generate_args(size)
    # Let's assume we have 10 times less products than orders
    [ Array.new(size / 10) { build_a_product() }, Array.new(size) { build_an_order() } ]
end

# Run the code on which we want to assert performance
def run(products, orders)
    match_products_with_orders(products, orders)
end
</code></pre>

<p>end</p>

<p>describe &ldquo;Products and Orders Matching&rdquo; do</p>

<pre><code>it "performs linearly" do
    # Verify that the code runs in time proportional to the size of its arguments
    expect(ProductOrdersMatching.new).to be_linear()
end
</code></pre>

<p>end
```</p>

<p>That&rsquo;s it ! If ever someone changes the code of <code>match_products_with_orders</code> and makes it perform worse than linearly, the assertion will fail ! There are similar assertions to check for constant and quadratic execution times.</p>

<p>Internally, the code will be called a number of times with different (smallish) sizes of arguments and the execution times will be logged. When this is over, by doing different flavors of linear regressions, it should determine whether the algorithm performs in O(1), O(n) or O(n²). Depending on your code, this can take time to run, but should still be faster than running large scale benchmarks.</p>

<p>Just check the <a href="https://github.com/philou/complexity-assert/blob/master/README.md">README</a> for more details.</p>

<h2>Did you say experiment ?</h2>

<p>It all started like an experiment. So the gem itself, is still experimental ! It&rsquo;s all fresh, and it could receive a lot of enhancements like :</p>

<ul>
<li>Allow the assertion to specify the sizes</li>
<li>Allow the assertion to specify the warm-up and run rounds</li>
<li>Robustness against garbage collection : use GC intensive ruby methods, and see how the regression behaves</li>
<li>Find ways to make the whole thing faster</li>
<li>O(lnx) : pre-treat with exp()</li>
<li>O(?lnx) : use exp, then a search for the coefficient (aka polynomial)</li>
<li>O(xlnx) : there is no well known inverse for that, we can compute it numerically though</li>
<li>Estimate how much the assert is deterministic</li>
<li>&hellip;</li>
</ul>


<p>As you see, there&rsquo;s a lot of room for ideas and improvements.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How NOT to use mocks, my talk at Paris.rb]]></title>
    <link href="http://philippe.bourgau.net/how-not-to-use-mocks-my-talk-at-paris-rb/"/>
    <updated>2016-09-13T04:03:00+00:00</updated>
    <id>http://philippe.bourgau.net/how-not-to-use-mocks-my-talk-at-paris-rb</id>
    <content type="html"><![CDATA[<p>As I already <a href="/blog/categories/mocking/">wrote about</a>, mocks can be trecherous &hellip; I gave a talk about how to avoid them last tuesday at <a href="http://www.meetup.com/fr-FR/parisrb/">Paris.rb meetup</a>. Here are the <a href="https://docs.google.com/presentation/d/1OH3eBgjyMcpupUnGWsHXm7kQjkckFpnJStYYYqBL6Yk/edit?usp=sharing">slides</a>.</p>

<p>It talks about testing, mocking, but also <a href="https://en.wikipedia.org/wiki/Domain-driven_design">Domain Driven Design</a> and <a href="https://wincent.com/blog/proxies-with-rr">test proxies à la RR</a> (but for rspec).</p>

<iframe src="https://docs.google.com/presentation/d/1OH3eBgjyMcpupUnGWsHXm7kQjkckFpnJStYYYqBL6Yk/embed?start=false&loop=false&delayms=3000" frameborder="0" width="790" height="470" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>




<p><p/>
Check the speaker&rsquo;s comments for all the details.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RSpecProxies now supports .to receive(xxx)... syntax]]></title>
    <link href="http://philippe.bourgau.net/rspecproxies-now-supports-to-receive-xxx-dot-dot-dot-syntax/"/>
    <updated>2016-08-23T04:47:00+00:00</updated>
    <id>http://philippe.bourgau.net/rspecproxies-now-supports-to-receive-xxx-dot-dot-dot-syntax</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/2016-08-23-rspecproxies-now-supports-to-receive-xxx-dot-dot-dot-syntax/test_probes.jpg" title="Hardware test probes" ></p>

<p>Pure mocks are dangerous. They let defect go through, give a false sense of security and are difficult to maintain.</p>

<p>I&rsquo;ve already talked about it <a href="/hitting-the-middle-ground-between-classicist-and-mockist-tdd/">before</a> but since then, <a href="http://david.heinemeierhansson.com/2014/tdd-is-dead-long-live-testing.html">DHH announced that he was quitting TDD</a>, the <a href="http://martinfowler.com/articles/is-tdd-dead/">Is TDD Dead ?</a> debate took place, and the conclusion is that <a href="https://www.thoughtworks.com/insights/blog/mockists-are-dead-long-live-classicists">mockist are dead</a>.</p>

<p>They are still times when mocks feel much simpler than any other things. For example, imagine your process leaks and crashes after 10 hours, the fix is to pass an option to a thirdparty, how would you test this in a fast test ? That&rsquo;s exactly the kind of situation where using test proxies saves you from mocks. A test proxy defers everything to the real object but also features unintrusive hooks and probes that you can use in your test. If you want a code example, check <a href="https://github.com/philou/mes-courses/commit/2c9fce17f9b59d0b3828f309015c07b17cceddf4?diff=split">this commit</a>, where I refactored a rails controller test from mocks to a RSpecProxies (v0.1).</p>

<p>I created RSpecProxies <a href="/my-new-gem-for-creating-rspec-proxies/">a while ago</a>, a while ago, and it&rsquo;s syntax made it alien to the RSpec work, it needed an update. <a href="http://rspec.info">RSpec</a> now supports basic proxying with partial stubs, spies, the <code>and_call_original</code> and the <code>and_wrap_original</code> methods. <a href="https://github.com/philou/rspecproxies">RSpecProxies 1.0</a> is a collection of hooks built on top of these to make proxying easier, with a syntax that will be familiar to RSpec users.</p>

<h2>Before original hook</h2>

<p>This hook is triggered before a call a method. Suppose you want to simulate a bad connection :</p>

<p>```ruby
it &lsquo;can simulate unreliable connection&rsquo; do
  i = 0
  allow(Resource).to receive(:get).and_before_calling_original { |*args|</p>

<pre><code>i += 1
raise RuntimeError.new if i % 3 == 0
</code></pre>

<p>  }</p>

<p>  resources = Resource.get_at_least(10)</p>

<p>  expect(resources.size).to eq(10)
end
```</p>

<h2>After original hooks</h2>

<p>RSpecProxies provides the same kind of hook after the call :</p>

<p>``` ruby
it &lsquo;can check that the correct data is used (using and_after_calling_original&rsquo; do
  user = nil
  allow(User).to receive(:load).and_after_calling_original { |result| user = result }</p>

<p>  controller.login(&lsquo;joe&rsquo;, &lsquo;secret&rsquo;)</p>

<p>  expect(response).to include(user.created_at.to_s)
end
```</p>

<p>Here we are capturing the return value to use it later in the test. For this special purpose, RSpecProxies also provides 2 other helpers :</p>

<p>``` ruby</p>

<h1>Store the latest result in @user of self</h1>

<p>allow(User).to receive(:load).and_capture_result_into(self, :user)</p>

<h1>Collect all results in the users array</h1>

<p>users = []
allow(User).to receive(:load).and_collect_results_into(users)
```</p>

<h2>Proxy chains</h2>

<p>RSpec mocks provides the <code>message_chain</code> feature to do build chains of stubs. RSpecProxy provides a very similar proxy chain concept. The main difference is that it creates proxies along the way, and not pure stubs. Pure stubs assume that you are mocking everything, but as our goal is to mock as little as possible, using proxies makes more sense.</p>

<p>When using a mockist approach, the message chain is a bad smell because it makes your tests very brittle by depending on a lot of implementation. In contrast, proxy chains are meant to be used where they are the simplest way to inject what you need, without creating havoc.</p>

<p>For example, suppose you want to display the progress of a very slow background task. You could mock a lot of your objects to have a fast test, of if you wanted to avoid all the bad side effects of mocking, you could run the background task in your test, and have a slow test &hellip; Or, you could use a chain of proxies :</p>

<p>``` ruby
it &lsquo;can override a deep getter&rsquo; do
  allow(RenderingTask).to proxy_message_chain(&ldquo;load.completion_ratio&rdquo;) { |e| e.and_return(0.2523) }</p>

<p>  controller.show</p>

<p>  expect(response).to include(&lsquo;25%&rsquo;)
end
```</p>

<p>Here the simplest thing to do is just to override a small getter, because from a functionnal point of view, that&rsquo;s exactly what we want to test.</p>

<h2>Last word</h2>

<p>The code is on <a href="https://github.com/philou/rspecproxies">github</a>, v1.0.0 is on <a href="https://rubygems.org/gems/rspecproxies/versions/0.1.0">rubygems</a>, it requires Ruby v2.2.5 and RSpec v3.5, the license is MIT, help in any form are welcome !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to prepare a new Ruby env in 3 minutes using Docker]]></title>
    <link href="http://philippe.bourgau.net/how-to-prepare-a-new-ruby-env-in-3-minutes-using-docker/"/>
    <updated>2016-08-17T05:21:00+00:00</updated>
    <id>http://philippe.bourgau.net/how-to-prepare-a-new-ruby-env-in-3-minutes-using-docker</id>
    <content type="html"><![CDATA[<p>One or two weeks ago, I registered to the <a href="http://www.meetup.com/fr-FR/Paris-Ruby-Workshop/">Paris Ruby Workshop Meetup</a> and needed a Ruby env. I have been using <a href="https://www.vagrantup.com/">Vagrant</a> quite a lot to isolate my different dev envs from each other and from my main machine. As I&rsquo;ve been digging more into <a href="http://www.docker.com">Docker</a> lately, I thought I&rsquo;d simply use Docker and Docker Compose instead.</p>

<p>I turned out to be dead simple. All that is needed is a <code>docker-compose.yml</code> file to define the container, record the shared volume and set a bundle path inside it :</p>

<p>```yaml
rubybox:
  image: ruby:2.3
  command: bash
  working_dir: /usr/src/app
  environment:</p>

<pre><code>BUNDLE_PATH: 'vendor/bundle'
</code></pre>

<p>  volumes:</p>

<pre><code>- '.:/usr/src/app'
</code></pre>

<p>```</p>

<p>Without the custom bundle path, bundled gems would be installed elsewhere in the container, and lost at every restart.</p>

<p>To use the Rubybox, just type <code>docker-compose run rubybox</code> and you&rsquo;ll get a shell from within your ruby machine, where you can do everything you want.</p>

<p>In fact, I found the thing so useful, that I created the <a href="https://github.com/philou/rubybox">Rubybox</a> git repo to simplify cloning and reusing. I&rsquo;ve already cloned it at least 3 times since then !</p>

<p><code>bash
git clone git@github.com:philou/rubybox.git
cd rubybox
docker-compose run rubybox
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Most Common Ways To Speed up an algorithm]]></title>
    <link href="http://philippe.bourgau.net/most-common-ways-to-speed-up-an-algorithm/"/>
    <updated>2016-01-20T05:14:00+00:00</updated>
    <id>http://philippe.bourgau.net/most-common-ways-to-speed-up-an-algorithm</id>
    <content type="html"><![CDATA[<p>Algorithms are <em>hard</em>, and making them fast is even harder &hellip; But there are shortcuts that work quite often !</p>

<p><img class="center" src="/imgs/2016-01-20-most-common-ways-to-speed-up-an-algorithm/shortcut-road.jpg" title="A street panel called Short Cut Road" ></p>

<h2>The Challenge</h2>

<p>Imagine you just arrived to your new job, and you are asked to make a part of the system faster. After a bit of investigation, you discover that most of the time is spent in some weird in-house algorithm that seems to take forever. How can you optimize this without deep knowledge neither in algorithm science nor in the code itself ?</p>

<p>Here are 4 tricks to reduce the complexity of algorithms (I&rsquo;m using fairly basic examples for the sake of understandably. Most of these exact examples could be done better using standard libraries, but I hope it will be easy to adapt to other situations) :</p>

<h3>Replace a nested loop by first building a hash and then looping</h3>

<p>```ruby</p>

<h1>before</h1>

<p>orders.each do |order|
  client = list_of_clients.find {|client| client.id = order.client_id }
  handle_order(order, client)
end</p>

<h1>after</h1>

<p>clients_by_id = {}
list_of_clients.each do |client|
  clients_by_id[client.id] = client
end
orders.each do |order|
  handle_order(order, clients_by_id[order.client_id])
end
```
This reduces the complexity from O(2) to O(1). This is tremendous. On large lists O(2) algorithms are terrible.</p>

<h3>Remove unnecessary accumulations</h3>

<p>The most classic example is the use of a string buffer :</p>

<p>```ruby
// Before
report = &ldquo;&rdquo;
line_items.each do |line_item|
  report += line_item.to_s + &ldquo;\n&rdquo;
end</p>

<p>// After
report = []
line_items.each do |line_item|
  report &lt;&lt; line_item.to_s
  report &lt;&lt; &ldquo;\n&rdquo;
end
report.join
```
Again, this reduces the complexity from O(2) to O(1). Every language has variants of Java&rsquo;s StringBuilders. This does not only apply for strings, it works any time you are repeatedly accumulating results inside a loop but where you could do it only once at the end.</p>

<h3>Cache intermediate or previous results</h3>

<p>This is called <a href="https://en.wikipedia.org/wiki/Memoization">memoization</a>. Some algorithms (especially recursive algorithms) repeatedly compute the same thing again and again. Spotting this pattern is an opportunity to move an algorithm out of exponential complexity. For example, <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijsktra&rsquo;s algorithm</a> for finding the shortest path in a graph uses this technique to go from O(e<sup>n</sup>) to O(n<sup>2</sup>) complexity. If you suspect this could be helpful, your best friend is logging to trace actual parameters and results.</p>

<p><a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#/media/File:Dijkstras_progress_animation.gif"><img class="center" src="/imgs/2016-01-20-most-common-ways-to-speed-up-an-algorithm/Dijkstras_progress_animation.gif" title="Dijsktra&rsquo;s path finding algorithm animated (from Wikipedia)" ></a></p>

<p>A word of caution : using memoization with mutable inputs or outputs will harm your mental health.</p>

<h3><a href="https://en.wikipedia.org/wiki/Merge_algorithm#Merging_two_lists">Zip merge</a></h3>

<p>There are 2 ways to merge sorted lists into a unique sorted list : the fast, and the slow &hellip;</p>

<p>```ruby</p>

<h1>The slow</h1>

<p>(list_1 + list_2).sort</p>

<h1>The fast</h1>

<p>i_1 = 0
i_2 = 0
result = []</p>

<p>while i_1 &lt; list_1.size and i_2 &lt; list_2.size
  if list_1[i_1] &lt;= list_2[i_2]</p>

<pre><code>result &lt;&lt; list_1[i_1]
i_1 += 1
</code></pre>

<p>  elsif list_2[i_2] &lt;= list_1[i_1]</p>

<pre><code>result &lt;&lt; list_2[i_2]
i_2 += 1
</code></pre>

<p>  end
end</p>

<p>while i_1 &lt; list_1.size
  result &lt;&lt; list_1[i_1]
  i_1 += 1
end</p>

<p>while i_2 &lt; list_2.size
  result &lt;&lt; list_2[i_2]
  i_2 += 1
end
```</p>

<p>Obviously, the slow version is a lot easier to read than the fast one. And the fast one could benefit from a bit of refactoring also &hellip; Nevertheless, the slow version is at best in O(n.ln(n)) whereas the fast on is in O(n). On large data, that can make a big difference.</p>

<h2>Is that all ?</h2>

<p>Obviously not, there can be a lot of other things going on slowly in algorithms, but from my experience, a software engineer can have a good career without knowing more about algorithms theory than that.</p>

<p>In the end, you manage to optimize this in-house algorithm, you become the company&rsquo;s hero, you need your job and get a pay raise !</p>

<h2>End word</h2>

<p>The fact is, in 15 years of writing software, I did not write a lot of algorithmic code. I can categories my working with algorithms in 3 :</p>

<ol>
<li>Write a simple algorithm for a non performance critical feature</li>
<li>Optimize an existing somewhat algorithmic part of code</li>
<li>Write a complex algorithm for a performance critical part of the system</li>
</ol>


<p>Case 1. is not really an issue since however the code will be written, it will run fast enough. If you&rsquo;re in case 3, there&rsquo;s no shortcut, you&rsquo;ll have to dig deep into algorithms and optimization, this happens rather rarely though. This leaves us with case 2, which I just wrote about.</p>

<p>Interestingly, <a href="http://www.murex.com">my current job</a> is deep into case 3 ! We&rsquo;re building a risk engine for corporate markets and are borrowing a lot of techniques from database science &hellip; which is, you can guess, rather algorithmic !</p>
]]></content>
  </entry>
  
</feed>
