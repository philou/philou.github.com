<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: open-source | Philippe Bourgau's blog]]></title>
  <link href="http://philippe.bourgau.net/blog/categories/open-source/atom.xml" rel="self"/>
  <link href="http://philippe.bourgau.net/"/>
  <updated>2017-02-08T18:05:09+00:00</updated>
  <id>http://philippe.bourgau.net/</id>
  <author>
    <name><![CDATA[Philippe Bourgau]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Verify the Big O Complexity of Ruby Code in RSpec]]></title>
    <link href="http://philippe.bourgau.net/verify-the-big-o-complexity-of-ruby-code-in-rspec/"/>
    <updated>2017-01-04T17:48:00+00:00</updated>
    <id>http://philippe.bourgau.net/verify-the-big-o-complexity-of-ruby-code-in-rspec</id>
    <content type="html"><![CDATA[<p>It might be possible to discover performance regressions before running your long and large scale benchmarks !</p>

<p><a href="https://github.com/philou/complexity-assert">complexity_assert</a> is an <a href="http://rspec.info/">RSpec</a> library that determines and checks the <a href="http://bigocheatsheet.com/">big O complexity</a> of a piece of code. Once you&rsquo;ve determined the performance critical sections of your system, you can use it to verify that they perform with the complexity you expect.</p>

<h2>How does it work ?</h2>

<p>The gem itself is the result of an experiment to learn machine learning in 20 hours (you can read more about that experiment in <a href="/how-i-got-my-feet-wet-with-machine-learning-with-the-first-20-hours/">my previous post</a> if you want).</p>

<p>Suppose you have some a method, let&rsquo;s call it <code>match_products_with_orders(products, orders)</code> which is called in in one of your processes with very large arguments. Badly written, this method could be quadratic (O(n²)), which would lead to catastrophic performances in production. When coding it, you&rsquo;ve taken particular care to make it perform in linear time. Unfortunately, it could easily slip back to a slower implementation with a bad refactoring &hellip; Using complexity_assert, you can make sure that this does not happen :</p>

<p>``` ruby</p>

<h1>An adapter class to fit the code to measure in complexity assert</h1>

<p>class ProductsOrdersMatching</p>

<pre><code># Generate some arguments of a particular size
def generate_args(size)
    # Let's assume we have 10 times less products than orders
    [ Array.new(size / 10) { build_a_product() }, Array.new(size) { build_an_order() } ]
end

# Run the code on which we want to assert performance
def run(products, orders)
    match_products_with_orders(products, orders)
end
</code></pre>

<p>end</p>

<p>describe &ldquo;Products and Orders Matching&rdquo; do</p>

<pre><code>it "performs linearly" do
    # Verify that the code runs in time proportional to the size of its arguments
    expect(ProductOrdersMatching.new).to be_linear()
end
</code></pre>

<p>end
```</p>

<p>That&rsquo;s it ! If ever someone changes the code of <code>match_products_with_orders</code> and makes it perform worse than linearly, the assertion will fail ! There are similar assertions to check for constant and quadratic execution times.</p>

<p>Internally, the code will be called a number of times with different (smallish) sizes of arguments and the execution times will be logged. When this is over, by doing different flavors of linear regressions, it should determine whether the algorithm performs in O(1), O(n) or O(n²). Depending on your code, this can take time to run, but should still be faster than running large scale benchmarks.</p>

<p>Just check the <a href="https://github.com/philou/complexity-assert/blob/master/README.md">README</a> for more details.</p>

<h2>Did you say experiment ?</h2>

<p>It all started like an experiment. So the gem itself, is still experimental ! It&rsquo;s all fresh, and it could receive a lot of enhancements like :</p>

<ul>
<li>Allow the assertion to specify the sizes</li>
<li>Allow the assertion to specify the warm-up and run rounds</li>
<li>Robustness against garbage collection : use GC intensive ruby methods, and see how the regression behaves</li>
<li>Find ways to make the whole thing faster</li>
<li>O(lnx) : pre-treat with exp()</li>
<li>O(?lnx) : use exp, then a search for the coefficient (aka polynomial)</li>
<li>O(xlnx) : there is no well known inverse for that, we can compute it numerically though</li>
<li>Estimate how much the assert is deterministic</li>
<li>&hellip;</li>
</ul>


<p>As you see, there&rsquo;s a lot of room for ideas and improvements.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[3 More Great Talks From JavaOne 2016]]></title>
    <link href="http://philippe.bourgau.net/3-more-great-talks-from-javaone-2016/"/>
    <updated>2016-10-14T04:05:00+00:00</updated>
    <id>http://philippe.bourgau.net/3-more-great-talks-from-javaone-2016</id>
    <content type="html"><![CDATA[<p>After the top <a href="/top-5-talks-i-attented-at-java-one-2016-part-1/">5 talks I attended at JavaOne</a> here are more !</p>

<h2>Managing Open Source Contributions in Large Organizations</h2>

<p><a href="http://www.jamesward.com/presos">James Ward</a></p>

<p>This talk was very interesting for companies or organizations that want to use Open Source in some way without ignoring the risks.</p>

<p>After an introduction listing the benefits of contributing to open source, James explained the associated risks :</p>

<ul>
<li>Security (evil contributions or information leaks)</li>
<li>Quality (bad contributions, increased maintenance or showing a bad image)</li>
<li>Legal (responsibility in case of patent infringing contribution, ownership of a contribution, licenses)</li>
</ul>


<p>He then explained that there are 3 ways to deal with the issue :</p>

<table>
<thead>
<tr>
<th> Strategy </th>
<th> Description </th>
<th> Pros </th>
<th> Cons </th>
<th> Popularity </th>
<th> Examples </th>
</tr>
</thead>
<tbody>
<tr>
<td> Do nothing </td>
<td> Devs just contribute without saying it </td>
<td> Easy, Gets it done </td>
<td> Need to stay under the radar, Risks for all parties are ignores </td>
<td> +++++ </td>
<td> Most open source code on <a href="https://github.com">Github</a> is shared in this manner |</td>
</tr>
<tr>
<td> Join a foundation </td>
<td> Joining an existing open source foundation, with a framework </td>
<td> Everything out of the box (infra, governance), builds trust </td>
<td> Rules can be heavy, Ownership is given to the foundation </td>
<td> +++ </td>
<td> <a href="https://www.linkedin.com/">Linkedin</a> put <a href="https://kafka.apache.org/">Kafka</a> in the <a href="https://www.apache.org/">Apache Foundation</a> |</td>
</tr>
<tr>
<td> Build tools </td>
<td> Use your own tools to mitigate the main risks associated with the &lsquo;Do nothing&rsquo; strategy </td>
<td> Built on top of Github, Keep control, Keeps things easy </td>
<td> Need to develop, test and operate the tools </td>
<td> + </td>
<td> Demo of a tool plugged into Github to enforce a contributor license agreement for anyone pushing a pull request |</td>
</tr>
</tbody>
</table>


<p><a href="/imgs/2016-10-14-3-more-great-talks-from-javaone-2016/CLA.jpg">{% img center /imgs/2016-10-14-3-more-great-talks-from-javaone-2016/CLA-small.jpg Slide with a Github capture for Contributor License Agreement %}</a></p>

<p>The &lsquo;build tools&rsquo; strategy looks promising, even if it is not yet widely used !</p>

<p>Here are <a href="https://www.youtube.com/watch?v=X71HrW6vC_0">the talk</a> and <a href="http://presos.jamesward.com/managing_open_source_contributions_in_large_orgs/index.html#/">the slides</a> on the authors website.</p>

<h2>Java Performance Analysis in Linux with Flame Graphs</h2>

<p><a href="http://www.brendangregg.com/">Brendan Gregg</a></p>

<p>This is what a flame graph looks like :</p>

<p><a href="http://www.brendangregg.com/FlameGraphs/cpu-mixedmode-vertx.svg">{% img center /imgs/2016-10-14-3-more-great-talks-from-javaone-2016/flamegraph.png An example of a Java flame graph %}</a></p>

<p>Technically, it&rsquo;s just an SVG with some Javascript. It shows the performance big picture. It aggregates data from Linux and JVM profilers. Vertically, you can see the call stacks in your system. The larger a block, the more time is taken inside a function (or in a sub call). The top border is where the CPU time is actually taken. If you want to speed up your system, speed up the wider zones at the top of the graph.</p>

<p>At <a href="https://www.netflix.com">Netflix</a>, the speaker is a performance engineer, and his job is to build tools to help other teams discover performance issues. This is how they use Flame Graphs :</p>

<ul>
<li>Compare 2 flame graphs at different times to see what changed</li>
<li>Do a <a href="http://martinfowler.com/bliki/CanaryRelease.html">canary release</a> and compare the new flame graph before finishing the deployment</li>
<li>Taking continuous flame graphs on running services helps identify JVM behavior like JIT or GC</li>
<li>They use different color themes to highlight different things</li>
<li>They also use them to identify CPU cache misses</li>
</ul>


<p>By the way, I also thought this was a great example of using an innovative visualization to manage tons of data.</p>

<p>I could find neither the video nor the slides of the talk, but I managed to find a lot of <a href="https://www.google.fr/search?safe=active&amp;client=ubuntu&amp;espv=2&amp;biw=1600&amp;bih=810&amp;tbm=vid&amp;q=Flame+Graphs&amp;oq=Flame+Graphs&amp;gs_l=serp.3...1396.1396.0.1616.1.1.0.0.0.0.59.59.1.1.0....0...1c.1.64.serp..0.0.0.z-3ygDHx4-Q">others talks about Flame Graphs</a>, as well as extra material on <a href="http://www.brendangregg.com/flamegraphs.html">the speaker&rsquo;s homepage</a>.</p>

<h2>Increasing Code Quality with Gamification</h2>

<p><a href="https://twitter.com/alex90_ch">Alexander Chatzizacharias</a></p>

<p>You might be wondering why we should care about gamification ?</p>

<ul>
<li>Worldwide 11.2 billion hours are spent playing every week !</li>
<li>People love to play because it makes them feel awesome</li>
<li>Games are good teachers</li>
<li>At work we are the ones who need to make others successful</li>
<li>But only 32% of workers are engaged in their work !</li>
</ul>


<p>Games rely on 4 main dynamics :</p>

<ul>
<li>Competition (be very careful of closed economics which can be very bad for teams)</li>
<li>Peer pressure (Public stats push teams and individual to conform to the norm)</li>
<li>Progression (regular recognition of new skills is motivating)</li>
<li>Rewards (Badges, Level ups, Monkey Money, real money &hellip;)</li>
</ul>


<p>He went on to demonstrate two games that are based on Jenkins and Sonar that aim at better code quality :</p>

<ul>
<li>One mobile app developed during a 24h Hackathon at CGI which might be open sourced at some point</li>
<li>Another one called &lsquo;Dev Cube&rsquo; created at an university, where you get to decorate you virtual cubicle</li>
</ul>


<p><a href="https://www.youtube.com/watch?v=hfT2_HxOQdk">{% img center /imgs/2016-10-14-3-more-great-talks-from-javaone-2016/quincy-adams.jpg The speaker demoing his code quality game %}</a></p>

<p>At the end of the talk, he gave the following recommendations :</p>

<ul>
<li>Understand the needs of all to respond to everyone&rsquo;s personal goals</li>
<li>Don&rsquo;t assign things to do, that&rsquo;s not fun, give rewards instead</li>
<li>Keep managers out of the picture</li>
<li>To keep it going, you need regular improvements, special events and new rules</li>
<li>KISS !</li>
</ul>


<p>Playing at work might not be unproductive in the end !</p>

<p>The same <a href="https://www.youtube.com/watch?v=hfT2_HxOQdk">talk given at NLJug</a>, unfortunately, it&rsquo;s in Dutch. English slides are <a href="https://static.rainfocus.com/oracle/oow16/sess/14625567983370011wPS/ppt/increasing%20code%20quality%20with%20gamification.pdf">here</a> though.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automatic Travis daily build with Heroku scheduler]]></title>
    <link href="http://philippe.bourgau.net/automatic-travis-daily-build-with-heroku-scheduler/"/>
    <updated>2014-03-24T06:31:00+00:00</updated>
    <id>http://philippe.bourgau.net/automatic-travis-daily-build-with-heroku-scheduler</id>
    <content type="html"><![CDATA[<p>As <a href="/auchandirect-scrapi-an-unofficial-api-ruby-gem/">I just released</a> <a href="https://github.com/philou/auchandirect-scrAPI">auchandirect-scrAPI</a>, and that it relies on scrapping, I needed a daily build.</p>

<p>The <a href="https://travis-ci.org">Travis</a> team <a href="https://github.com/travis-ci/travis-ci/issues/582">is already working</a> on this, and I found a small utility app called <a href="http://traviscron.pythonanywhere.com/">TravisCron</a> where anyone can register his repo for an automatic build.</p>

<p>Unfortunately, the feature is not yet ready in Travis, and the TravisCron guys did not yet activate my repo. After having a look at the <a href="https://github.com/FiloSottile/travis-cron">TravisCron source code</a> and the <a href="https://github.com/travis-ci/travis.rb">Travis API</a>, I found out that it is really simple to do the same thing on my own.</p>

<p>That&rsquo;s how I created <a href="https://github.com/philou/daily-travis">daily-travis</a>. It&rsquo;s a tiny Rake task, ready to be pushed and automaticaly scheduled on heroku that will restart the latest build when run.</p>

<p>Details are in the <a href="https://github.com/philou/daily-travis/blob/master/README.md">README</a></p>

<p>@Travis : Thanks again for your service.</p>

<p>{% img center /imgs/2014-03-24-automatic-travis-daily-build-with-heroku-scheduler/travis-ci.jpeg I love Travis logo %}</p>
]]></content>
  </entry>
  
</feed>
