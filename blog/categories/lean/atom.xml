<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: lean | Philippe Bourgau's blog]]></title>
  <link href="http://philippe.bourgau.net/blog/categories/lean/atom.xml" rel="self"/>
  <link href="http://philippe.bourgau.net/"/>
  <updated>2015-05-26T04:19:40+00:00</updated>
  <id>http://philippe.bourgau.net/</id>
  <author>
    <name><![CDATA[Philippe Bourgau]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[What Optimization Should We Work On (Lean Software Development Part 5)]]></title>
    <link href="http://philippe.bourgau.net/what-optimization-should-we-work-on-lean-software-development-part-5/"/>
    <updated>2015-03-26T20:30:00+00:00</updated>
    <id>http://philippe.bourgau.net/what-optimization-should-we-work-on-lean-software-development-part-5</id>
    <content type="html"><![CDATA[<p>At work, we are building a risk aggregation system. As it&rsquo;s dealing with a large bunch of numbers, it&rsquo;s a huge heap of optimizations. Once that its most standard features set is supported, our job mostly consists of making it faster.</p>

<p>That&rsquo;s were we are now doing.</p>

<p>{% img center /imgs/2015-03-26-what-optimization-should-we-work-on-lean-software-development-part-5/turtle.jpg A turtle with a rocket on the back %}</p>

<h1>How do we choose which optimization to work on ?</h1>

<p>The system still being young, we have a wide range of options to optimize it. To name just a few : caches, better algorithms, better low level hardware usage &hellip;</p>

<p>It turns out that we can use the speedup factor as a substitute for business value and use known techniques to help us to make the best decisions.</p>

<h2>Let&rsquo;s walk through an example</h2>

<h3>I. List the optimizations you are thinking of</h3>

<p>Let&rsquo;s suppose we are thinking of the following 3 optimizations for our engine</p>

<ul>
<li>Create better data structures to speed up the reconciliation algorithm</li>
<li>Optimize the reconciliation algorithm itself to reduce CPU cache misses</li>
<li>Minimize boxing and unboxing</li>
</ul>


<h3>II. Poker estimate the story points and speedup</h3>

<p>Armed with these stories, we can poker estimate them, by story points and by expected speedup.
As a substitute for WSJF, we will then be able to compute the speedup rate per story point.
We will then just have to work on the stories with the highest speedup rate first.</p>

<table>
<thead>
<tr>
<th>Title                   </th>
<th> Story Points  </th>
<th> /10    </th>
<th> /2     </th>
<th> -10%    </th>
<th> ~  </th>
<th> +10%   </th>
<th> x2      </th>
<th> x10     </th>
<th> Expected Speedup ratio* </th>
<th> Speedup rate / story point**</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Structures     </td>
<td> 13        </td>
<td>        </td>
<td>        </td>
<td>             </td>
<td>        </td>
<td> 4 votes</td>
<td> 5 votes </td>
<td>         </td>
<td> x 1.533                 </td>
<td> x 1.033</td>
</tr>
<tr>
<td>Algorithm           </td>
<td> 13        </td>
<td>    </td>
<td> 1 vote </td>
<td> 1 vote      </td>
<td> 2 votes</td>
<td> 1 vote </td>
<td> 2 votes </td>
<td> 2 votes </td>
<td> x 1.799                 </td>
<td> x 1.046</td>
</tr>
<tr>
<td>Boxing                  </td>
<td> 8     </td>
<td>    </td>
<td>        </td>
<td>             </td>
<td>        </td>
<td> 9 votes</td>
<td>         </td>
<td>         </td>
<td> x 1.1                   </td>
<td> x 1.012</td>
</tr>
</tbody>
</table>


<p><sup><em>* Expected speedup ratio is the logarithmic average of the voted speedups</em></sup><br>
<sup><em>** Speedup rate is &ldquo;speedup<sup>(1/ story points)</sup>&rdquo;</em></sup></p>

<p>So based on speedup rate, here is the order in which we should perform the stories :</p>

<ol>
<li>Algorithm</li>
<li>Data Structures</li>
<li>Boxing</li>
</ol>


<h3>III. And what about the risks ?</h3>

<p>{% img center /imgs/2015-03-26-what-optimization-should-we-work-on-lean-software-development-part-5/danger.jpg A danger zone panel %}</p>

<p>This poker estimation tells us something else &hellip;</p>

<blockquote><p>We don&rsquo;t have a clue about the speedup we will get by trying to optimize the algorithm !</p></blockquote>

<p>The votes range from /2 to x10 ! This is the perfect situation for an XP spike.</p>

<table>
<thead>
<tr>
<th>Title </th>
<th> Story points </th>
<th> Expected Speedup rate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Algorithm spike : measure out of context CPU cache optimization speedup </td>
<td> 2 </td>
<td>   ?</td>
</tr>
</tbody>
</table>


<br>


<p>In order to compute the expected speedup rate, let&rsquo;s suppose that they are 2 futures, one where we get a high speedup and another where we get a low one.</p>

<p>They are computed by splitting the votes in 2 :</p>

<ul>
<li><em>low_speedup = 0.846</em></li>
<li><em>high_speedup = 3.827</em></li>
</ul>


<h4>If the spike succeeds</h4>

<p>We&rsquo;ll first work on the spike, and then on the algorithm story. In the end, we would get the speedup of the algorithm optimization.</p>

<ul>
<li><em>spike_high_speedup = high_speedup = 3.827</em></li>
</ul>


<h4>If the spike fails</h4>

<p>We&rsquo;ll also start by working on the spike. Afterwards, instead of the algorithm story, we&rsquo;ll tackle another optimization stories, yielding our average speedup rate for the duration of the algorithm story. The average speedup rate can be obtained from historical benchmark data, or by averaging the speedup rate of the other stories.</p>

<ul>
<li><em>average_speedup_rate = (1.033 * 1.011)<sup>&frac12;</sup> = 1.022</em></li>
<li><em>spike_low_speedup = average_speedup_rate<sup>story_points</sup> = 1.02213 = 1.326</em></li>
</ul>


<h4>Spike speedup rate</h4>

<p>We can now compute the average expected speedup rate for the full period &lsquo;spike &amp; algorithm&rsquo; stories. From this we will be able to get the speedup rate and finally, to prioritize this spike against the other stories in our backlog.</p>

<ul>
<li><em>spike_speedup = (spike_low_speedup * spike_high_speedup)<sup>&frac12;</sup> = 2.253</em></li>
<li><em>spike_speedup_rate = spike_speedup<sup>1/(spike_story_points + algorithm_story_points)</sup> = 2.253<sup>1/(2 + 13)</sup> = 1.056</em></li>
</ul>


<h3>IV. Putting it all together</h3>

<p>Here are all the speedup rate for the different stories.</p>

<table>
<thead>
<tr>
<th>Title </th>
<th> Speedup rate / story point</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Structure  </td>
<td> x 1.033</td>
</tr>
<tr>
<td>Algorithm           </td>
<td> x 1.046</td>
</tr>
<tr>
<td>Boxing                  </td>
<td> x 1.012</td>
</tr>
<tr>
<td>Algorithm spike         </td>
<td> x 1.056</td>
</tr>
</tbody>
</table>


<br>


<p>Finally, here is the optimal order through which we should perform the stories :</p>

<ul>
<li>Algorithm spike</li>
<li>Algorithm (only if the spike proved it would work)</li>
<li>Data Structures</li>
<li>Boxing</li>
</ul>


<h2>Summary</h2>

<p>The math are not that complex, and a simple formula can be written to compute the spike speedup rate :</p>

<p>{% img center /imgs/2015-03-26-what-optimization-should-we-work-on-lean-software-development-part-5/poc_speedup_rate.png Formula for a spike speedup rate %}</p>

<p>I think most experienced engineers would have come to the same conclusion by gut feeling &hellip;</p>

<p>Nevertheless I believe that systematically applying the such method when prioritizing optimizations can lead to a greater speedup rate than the competition in the long run. This is a perfect example where taking measured risks can payoff !</p>

<p>This was part 5 of my <a href="/the-flow-book-summary-lean-software-development_part_1/">Lean Software Development Series</a>. Part 4 was <a href="/measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/">Measure the business value of your spikes and take high payoff risks</a>, Part 5 will be &ldquo;Measure the value of the lean startup &lsquo;learning&rsquo;&rdquo;.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Measure The Business Value of Your Spikes and Take High Payoff Risks (Lean Software Development Part 4)]]></title>
    <link href="http://philippe.bourgau.net/measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/"/>
    <updated>2015-01-31T15:13:00+00:00</updated>
    <id>http://philippe.bourgau.net/measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4</id>
    <content type="html"><![CDATA[<p>Lately <a href="http://www.murex.com">at work</a>, we&rsquo;ve unexpectedly been asked by other teams if they could use our product for something that we had not forseen. As we are not sure whether we&rsquo;ll be able to tune our product to their needs, we are thinking about doing a short study to know the answer. This looks like a great opportunity to try out <a href="http://en.wikipedia.org/wiki/Cost_of_delay">Cost of Delay</a> analysis about uncertain tasks.</p>

<p>Unfortunately, I cannot write the details of what we are creating at work in this blog, so let&rsquo;s assume that we are building a Todo List Software.</p>

<p>We have been targeting the enterprise market. Lately, we&rsquo;ve seen some interest from individuals planning to use our todo list system for themselves at home.</p>

<p>For individuals, the system would need to be highly available and live 24/7 over the internet, latency will also be critical to retain customers, but the product could get a market share with a basic feature set.</p>

<p>On the other side, enterprise customers need advanced features, absolute data safety, but they can cope with nightly restarts of the server.</p>

<p>In order to know if we can make our todo list system available and fast enough for the individuals market, we are planning to conduct a pre-study, so as not to waste time on an unreachable goal. In <a href="http://www.extremeprogramming.org/">XP</a> terms, this is a <a href="http://www.extremeprogramming.org/rules/spike.html">spike</a>, and it&rsquo;s a bunch of experiments rather than a theoretical study.</p>

<p><a href="/imgs/2015-01-31-measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/study.jpg">{% img center /imgs/2015-01-31-measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/study-petit.jpg Photo of someone studying behind piles of books%}</a></p>

<h2>When should we prioritize this spike ?</h2>

<p>If we are using the <a href="http://www.scaledagileframework.com/wsjf/">Weighted Shortest Job First</a> metric to prioritize our work, we need to estimate the cost of delay of a task to determine its priority. Hereafter I will explain how we could determine the value of this spike.</p>

<h2>Computing the cost of delay</h2>

<p>The strategy to compute the cost of delay for such a risk mitigation task is to compute the difference in cost of delays with or without doing it.</p>

<h3>1. The products, the features, the MVP and the estimates</h3>

<p>As I explained in <a href="/how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/">a previous post</a>, for usual features, cost of delay is equivalent to it&rsquo;s value. Along with our gross estimates, here are the relative values that our product owner gave us for the different products we are envisioning.</p>

<table>
<thead>
<tr>
<th>Feature                   </th>
<th> $ Enterprise </th>
<th> $ Individuals </th>
<th> Estimated work</th>
</tr>
</thead>
<tbody>
<tr>
<td>Robustness            </td>
<td> 20*          </td>
<td> 20*           </td>
<td> 2</td>
</tr>
<tr>
<td>Availability              </td>
<td> 0            </td>
<td> 40*           </td>
<td> 2</td>
</tr>
<tr>
<td>Latency                   </td>
<td> 0            </td>
<td> 40*           </td>
<td> 1</td>
</tr>
<tr>
<td>Durability            </td>
<td> 40*          </td>
<td> 13            </td>
<td> 2</td>
</tr>
<tr>
<td>Multi user lists          </td>
<td> 20*          </td>
<td> 8             </td>
<td> 2</td>
</tr>
<tr>
<td>Labels                    </td>
<td> 20           </td>
<td> 13            </td>
<td> 2</td>
</tr>
<tr>
<td>Custom report tool        </td>
<td> 13           </td>
<td> 0             </td>
<td> 3</td>
</tr>
<tr>
<td>TOTAL Cost Of Delay of v1 </td>
<td> 80           </td>
<td> 100           </td>
<td></td>
</tr>
</tbody>
</table>


<p><small>Stared (*) features are required for the first version of the product. Features with a value of 0 are not required for the product. Eventually, unstared features with a non null business value would be great for a second release.</small><br></p>

<p>It seems that the individuals market is a greater opportunity, so it&rsquo;s worth thinking about it. Unfortunately for the moment, we really don&rsquo;t know if we&rsquo;ll manage to get the high availability that is required for such a product.</p>

<p>The availability spike we are envisioning would take 1 unit of time.</p>

<h3>2. Computing the cost of delay of this spike</h3>

<p>The cost of delay of a task involving some uncertainty is the probabilistic expected value of its cost of delay. We estimate that we have 50% of chances of matching the availability required by individuals. It means that CoD of the spike = 50% * CoD if we match the latency + 50% CoD if we don&rsquo;t match the availability.</p>

<h4>2.a. The Cost of Delay if we get the availability</h4>

<p>Let&rsquo;s consider the future in which we&rsquo;ll manage to reduce the latency.
The cost of delay of a spike task is the difference in Cost with and without doing the spike, per relevent months.</p>

<h5>2.a.i. The cost if we don&rsquo;t do the spike</h5>

<p>Unfortunately, at this point in this future, we don&rsquo;t yet know that we&rsquo;ll manage to get to the availability.</p>

<table>
<thead>
<tr>
<th>Feature                   </th>
<th> $ Enterprise </th>
<th> $ Individuals </th>
<th> $ Expected   </th>
<th> Estimated work </th>
<th> WSJF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Latency                   </td>
<td> 0            </td>
<td> 40*           </td>
<td> 20           </td>
<td> 1              </td>
<td> 20</td>
</tr>
<tr>
<td>Durability            </td>
<td> 40*          </td>
<td> 13            </td>
<td> 26           </td>
<td> 2              </td>
<td> 13</td>
</tr>
<tr>
<td>Robustness            </td>
<td> 20*          </td>
<td> 20*           </td>
<td> 20           </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Availability              </td>
<td> 0            </td>
<td> 40*           </td>
<td> 20           </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Labels                    </td>
<td> 20           </td>
<td> 13            </td>
<td> 17           </td>
<td> 2              </td>
<td> 9</td>
</tr>
<tr>
<td>Multi user lists          </td>
<td> 20*          </td>
<td> 8             </td>
<td> 14           </td>
<td> 2              </td>
<td> 7</td>
</tr>
<tr>
<td>Custom report tool        </td>
<td> 13           </td>
<td> 0             </td>
<td> 8            </td>
<td> 3              </td>
<td> 3</td>
</tr>
</tbody>
</table>


<br>


<p>We&rsquo;ll resort to WSJF to prioritize our work. Here is what we&rsquo;ll be able to ship :</p>

<table>
<thead>
<tr>
<th>Product </th>
<th> Delay </th>
<th> CoD </th>
<th> Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Individuals                     </td>
<td> 7    </td>
<td> 100   </td>
<td>  700</td>
</tr>
<tr>
<td>Individuals Durability          </td>
<td> 7    </td>
<td> 13    </td>
<td>   91</td>
</tr>
<tr>
<td>Individuals Labels              </td>
<td> 9    </td>
<td> 13    </td>
<td>  117</td>
</tr>
<tr>
<td>Enterprise                      </td>
<td> 11   </td>
<td> 80    </td>
<td>  880</td>
</tr>
<tr>
<td>Enterprise labels               </td>
<td> 11   </td>
<td> 20    </td>
<td>  220</td>
</tr>
<tr>
<td>Individuals Multi user lists    </td>
<td> 13   </td>
<td> 8     </td>
<td>  104</td>
</tr>
<tr>
<td>Enterprise Custom reports       </td>
<td> 16   </td>
<td> 13    </td>
<td>  208</td>
</tr>
<tr>
<td>                                </td>
<td>      </td>
<td>       </td>
<td> 2320</td>
</tr>
</tbody>
</table>


<br>


<h5>2.a.ii. The cost if we do the spike</h5>

<p>In this case, we would start by the spike, and it would tell us that we can reach the individuals availability and so that we should go for this feature first. Here will be our planning</p>

<table>
<thead>
<tr>
<th>Feature                   </th>
<th> $ Enterprise </th>
<th> $ Individuals </th>
<th> Estimated work </th>
<th> Enterprise WSJF </th>
<th> Individuals WSJF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feasibility spike         </td>
<td>              </td>
<td>               </td>
<td> 1              </td>
<td>                 </td>
<td></td>
</tr>
<tr>
<td>Latency                   </td>
<td> 0            </td>
<td> 40*           </td>
<td> 1              </td>
<td>                 </td>
<td> 40</td>
</tr>
<tr>
<td>Availability              </td>
<td> 0            </td>
<td> 40*           </td>
<td> 2              </td>
<td>                 </td>
<td> 20</td>
</tr>
<tr>
<td>Robustness            </td>
<td> 20*          </td>
<td> 20*           </td>
<td> 2              </td>
<td> 10              </td>
<td> 10</td>
</tr>
<tr>
<td>Durability            </td>
<td> 40*          </td>
<td> 13            </td>
<td> 2              </td>
<td> 20              </td>
<td> 7</td>
</tr>
<tr>
<td>Multi user lists          </td>
<td> 20*          </td>
<td> 8             </td>
<td> 2              </td>
<td> 10              </td>
<td> 4</td>
</tr>
<tr>
<td>Labels                    </td>
<td> 20           </td>
<td> 13            </td>
<td> 2              </td>
<td> 10              </td>
<td> 7</td>
</tr>
<tr>
<td>Custom report tool        </td>
<td> 13           </td>
<td> 0             </td>
<td> 3              </td>
<td> 4               </td>
<td></td>
</tr>
</tbody>
</table>


<br>


<p>Here is how we will be able to ship :</p>

<table>
<thead>
<tr>
<th>Product </th>
<th> Delay </th>
<th> CoD </th>
<th> Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Individuals                     </td>
<td> 6    </td>
<td> 100   </td>
<td>  600</td>
</tr>
<tr>
<td>Individuals Durability          </td>
<td> 8    </td>
<td> 13    </td>
<td>  104</td>
</tr>
<tr>
<td>Individuals Multi user lists    </td>
<td> 10   </td>
<td> 8     </td>
<td>   80</td>
</tr>
<tr>
<td>Enterprise                      </td>
<td> 10   </td>
<td> 80    </td>
<td>  800</td>
</tr>
<tr>
<td>Individuals Labels              </td>
<td> 12   </td>
<td> 13    </td>
<td>  156</td>
</tr>
<tr>
<td>Enterprise Labels               </td>
<td> 12   </td>
<td> 20    </td>
<td>  240</td>
</tr>
<tr>
<td>Enterprise Custom reports       </td>
<td> 15   </td>
<td> 13    </td>
<td>  195</td>
</tr>
<tr>
<td>                                </td>
<td>      </td>
<td>       </td>
<td> 2175</td>
</tr>
</tbody>
</table>


<br>


<h5>2.a.iii. Cost of delay of the spike if we reach the availability</h5>

<p>By making the spike, we would save 2320 &ndash; 2175 = 145$</p>

<p>Without doing the spike, we would discover whether we would reach the availability when we try it, around time 7 (see 2.a.i).</p>

<p>So the cost of delay for the spike would be around 145/7 = 21 $/m</p>

<h4>2.b. The Cost of Delay if we don&rsquo;t get the availability</h4>

<p>Let&rsquo;s now consider the future in which we don&rsquo;t manage to increase the availability.</p>

<p>Using the same logic as before, let&rsquo;s now see what happens</p>

<h5>2.b.i. The cost if we don&rsquo;t do the spike</h5>

<p>Unfortunately, at this point in this future, we don&rsquo;t yet know that we&rsquo;ll not manage to get to the availability.</p>

<table>
<thead>
<tr>
<th>Feature                   </th>
<th> $ Enterprise </th>
<th> $ Individuals </th>
<th> $ Expected   </th>
<th> Estimated work </th>
<th> WSJF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Latency                   </td>
<td> 0            </td>
<td> 40*           </td>
<td> 20           </td>
<td> 1              </td>
<td> 20</td>
</tr>
<tr>
<td>Durability            </td>
<td> 40*          </td>
<td> 13            </td>
<td> 26           </td>
<td> 2              </td>
<td> 13</td>
</tr>
<tr>
<td>Robustness            </td>
<td> 20*          </td>
<td> 20*           </td>
<td> 20           </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Availability              </td>
<td> 0            </td>
<td> 40*           </td>
<td> 20           </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Multi user lists          </td>
<td> 20*          </td>
<td> 8             </td>
<td> 14           </td>
<td> 2              </td>
<td> 7</td>
</tr>
<tr>
<td>Labels                    </td>
<td> 20           </td>
<td> 13            </td>
<td> 17           </td>
<td> 2              </td>
<td> 9</td>
</tr>
<tr>
<td>Custom report tool        </td>
<td> 13           </td>
<td> 0             </td>
<td> 8            </td>
<td> 3              </td>
<td> 3</td>
</tr>
</tbody>
</table>


<br>


<p>When we&rsquo;ll fail at the availability, we&rsquo;ll switch multi user lists and labels to be able to ship to enterprises as quickly as possible.
Here is what we&rsquo;ll ship.</p>

<table>
<thead>
<tr>
<th>Product </th>
<th> Delay </th>
<th> CoD </th>
<th> Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Enterprise                      </td>
<td>  9   </td>
<td> 80    </td>
<td>  720</td>
</tr>
<tr>
<td>Enterprise Labels               </td>
<td> 11   </td>
<td> 20    </td>
<td>  220</td>
</tr>
<tr>
<td>Enterprise Custom reports       </td>
<td> 14   </td>
<td> 13    </td>
<td>  182</td>
</tr>
<tr>
<td>                                </td>
<td>      </td>
<td>       </td>
<td> 1122</td>
</tr>
</tbody>
</table>


<br>


<h5>2.b.ii. The cost if we do the spike</h5>

<p>In this case, we would start by the spike, and it would tell us that we won&rsquo;t match the availability required for individuals and so that that there&rsquo;s no need to run after this now.</p>

<table>
<thead>
<tr>
<th>Feature            </th>
<th> $ Enterprise </th>
<th> Estimated work </th>
<th> WSJF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feasibility spike  </td>
<td>              </td>
<td> 1              </td>
<td></td>
</tr>
<tr>
<td>Durability     </td>
<td> 40*      </td>
<td> 2              </td>
<td> 13</td>
</tr>
<tr>
<td>Robustness     </td>
<td> 20*      </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Multi user lists   </td>
<td> 20*          </td>
<td> 2              </td>
<td> 7</td>
</tr>
<tr>
<td>Labels             </td>
<td> 20           </td>
<td> 2              </td>
<td> 9</td>
</tr>
<tr>
<td>Custom report tool </td>
<td> 13           </td>
<td> 3              </td>
<td> 3</td>
</tr>
</tbody>
</table>


<br>


<p>Here is how we will be able to ship :</p>

<table>
<thead>
<tr>
<th>Product </th>
<th> Delay </th>
<th> CoD </th>
<th> Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>Enterprise                      </td>
<td>  7   </td>
<td> 80    </td>
<td>  560</td>
</tr>
<tr>
<td>Enterprise Labels               </td>
<td>  9   </td>
<td> 20    </td>
<td>  180</td>
</tr>
<tr>
<td>Enterprise Custom reports       </td>
<td> 12   </td>
<td> 13    </td>
<td>  156</td>
</tr>
<tr>
<td>                                </td>
<td>      </td>
<td>       </td>
<td>  896</td>
</tr>
</tbody>
</table>


<br>


<h5>2.b.iii. Cost of delay of the spike if we reach the availability</h5>

<p>By making the spike, we would save 1122 &ndash; 896 = 226$</p>

<p>As before, without doing the spike, we would discover whether we would get the availability when we try it, around time 7.</p>

<p>So the cost of delay for the spike is around 226/7 = 32 $/m</p>

<h4>2.c. Compute overall Cost of Delay of the Spike</h4>

<p><a href="/imgs/2015-01-31-measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/CoD.jpg">{% img center /imgs/2015-01-31-measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/CoD-petit.jpg Bank notes going through an hourglass%}</a></p>

<p>Given that we estimate that there is a 50% chances of making the latency, the overall expected cost of delay is</p>

<p>50% * 21 + 50% * 32 = 26.5 $/m</p>

<p>Inject the spike in the backlog</p>

<p>With the Cost of Delay of the spike, we can compute it&rsquo;s WSJF and prioritize it against other features.</p>

<table>
<thead>
<tr>
<th>Feature </th>
<th> $ Enterprise </th>
<th> $ Individuals </th>
<th> Expected $ </th>
<th> Estimated work </th>
<th> WSJF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Feasibility Spike         </td>
<td>              </td>
<td>               </td>
<td> 26.5         </td>
<td> 1              </td>
<td> 26.5</td>
</tr>
<tr>
<td>Latency                   </td>
<td> 0            </td>
<td> 40*           </td>
<td> 20           </td>
<td> 1              </td>
<td> 20</td>
</tr>
<tr>
<td>Durability            </td>
<td> 40*          </td>
<td> 13            </td>
<td> 26           </td>
<td> 2              </td>
<td> 13</td>
</tr>
<tr>
<td>Robustness            </td>
<td> 20*          </td>
<td> 20*           </td>
<td> 20           </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Availability              </td>
<td> 0            </td>
<td> 40*           </td>
<td> 20           </td>
<td> 2              </td>
<td> 10</td>
</tr>
<tr>
<td>Multi user lists          </td>
<td> 20*          </td>
<td> 8             </td>
<td> 14           </td>
<td> 2              </td>
<td> 7</td>
</tr>
<tr>
<td>Labels                    </td>
<td> 20           </td>
<td> 13            </td>
<td> 17           </td>
<td> 2              </td>
<td> 9</td>
</tr>
<tr>
<td>Custom report tool        </td>
<td> 13           </td>
<td> 0             </td>
<td> 8            </td>
<td> 3              </td>
<td> 3</td>
</tr>
</tbody>
</table>


<br>


<p>The spike comes at the top of our backlog. Which confirms our gut feeling.</p>

<h2>Conclusion</h2>

<p>Doing this long study confirmed classic rule of thumbs</p>

<ul>
<li>Don&rsquo;t develop many products at the same time</li>
<li>Do some Proof Of Concepts early before starting to work on uncertain features</li>
<li>Tackle the most risky features first</li>
</ul>


<p>By improving the inputs, we could get more quality results :</p>

<ul>
<li>If we had access to real sales or finance figures for the costs</li>
<li>If we did some sort of poker risk estimation instead of just guessing at 50% chances</li>
</ul>


<p>Obviously, the analysis itself is not perfect, but it hints to the good choices. And as <a href="http://reinertsenassociates.com/">Don Reinertsen</a> puts it, using an economical framework, the spread between people estimations goes down from <a href="http://leanmagazine.net/lean/cost-of-delay-don-reinertsen/">50:1</a> to 2:1 ! This seems a good alternative to the experience and gut feeling approach which :</p>

<ul>
<li>can trigger heated unfounded discussions</li>
<li>often means high dependence on the intuition of a single individual</li>
</ul>


<p>As everything is quantitative though, one could imagine that with other figures, we could have got to another conclusion, such as :</p>

<ul>
<li>The spike is not worth doing (it costs more than it might save)</li>
<li>The spike can wait a bit</li>
</ul>


<p><a href="http://dilbert.com/strip/2014-03-30">{% img center /imgs/2015-01-31-measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/dt140330.jpg A dilbert strip about gut feeling at work%}</a></p>

<p>This was part 4 of my <a href="/the-flow-book-summary-lean-software-development_part_1/">Lean Software Development Series</a>. Part 3 was <a href="/how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/">How to measure your speed with your business value</a>, continue on Part 5 : <a href="/what-optimization-should-we-work-on-lean-software-development-part-5/">What optimization should we work on ?</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to measure your speed with your business value ? (Lean Software Development Part 3)]]></title>
    <link href="http://philippe.bourgau.net/how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/"/>
    <updated>2014-10-16T07:07:00+00:00</updated>
    <id>http://philippe.bourgau.net/how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3</id>
    <content type="html"><![CDATA[<p>There is a french idiom that basicaly is</p>

<blockquote><p>No use to run, all that is needed is to start on time &hellip;</p></blockquote>

<p>an agile engineer would add</p>

<blockquote><p>&hellip; and to go in the good direction</p></blockquote>

<p>Indeed, velocity or mean cycle time as speed measures have their shortcomings :</p>

<ul>
<li>Can be falsified by story point inflation !</li>
<li>Does not tell the team or its product owner whether they are working on the right thing.</li>
</ul>


<p>Wouldn&rsquo;t it be great if we could track the business value we are creating instead ? Wouldn&rsquo;t it be more motivating for developpers to know how they are contributing to the bottom line ? Wouldn&rsquo;t it help various people to align inside the organization ?</p>

<h2>How to track and prioritize based on your business value</h2>

<p>From <a href="http://www.amazon.com/The-Principles-Product-Development-Flow/dp/1935401009/ref=sr_1_1?ie=UTF8&amp;qid=1413953773&amp;sr=8-1&amp;keywords=product+development+flow">Reinertsen&rsquo;s Flow book</a>, we learned that the cost of delay is the main driver of the value creation : the faster you deliver a feature, less you spend the cost of delay of that feature, the more value you are creating for your company. <a href="http://scaledagileframework.com/wsjf/">This article</a> suggests that the cost of delay can be computed with the following formula :</p>

<blockquote><p>cost of delay = f(user business value) + g(time criticality) + h(risk reduction opportunity)</p></blockquote>

<p><a href="http://fr.slideshare.net/jchyip/estimating-cost-of-delay/27">This other article</a> suggests that they are different types of tasks that corresponds to the different terms of the formula above.</p>

<p>{% img center /imgs/2014-10-16-how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/task-types.jpeg &ldquo;Different kind of tasks&rdquo; %}</p>

<p>Here is how we could link the 2 articles :</p>

<ul>
<li>Stories with deadlines : either through legal or market constraints, not doing this will put you out of business (&lsquo;time criticality&rsquo; in the formula)</li>
<li>Stories that influence the bottom line : by increasing the sales figures when delivered, or decreasing them when not delivered, which is kind of the same (&lsquo;user business value&rsquo; in the formula)</li>
<li>Risk reduction tasks : by mitigating risk or streamlining the process, these tasks actually improve the bottom line of other stories (&lsquo;risk reduction opportunity&rsquo; in the formula)</li>
</ul>


<p>The later type of task will be detailed in other articles. Let&rsquo;s focus on the two others.</p>

<h2>The case of the deadlined feature ?</h2>

<p>First, I&rsquo;d say its business value is 0, until it&rsquo;s too late. You should not be working on it too soon, but you should not be working on it too late neither !</p>

<p>In his book <a href="http://www.amazon.com/Art-Agile-Development-James-Shore/dp/0596527675/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1413954965&amp;sr=1-1&amp;keywords=the+art+of+agile+development">The Art of Agile Development</a> James Shore details in great details how an agile team can commit to deliverables (I really recommend this part, I might even write a post about it). He explains that in order to commit, teams should multiply their estimates by 4, or by 1.8 if they are very rigourous in their application of all the XP practices.</p>

<p>So a rule to handle such a task could be to</p>

<ul>
<li>estimate it</li>
<li>multiply that estimate by 4</li>
<li>substract this time from the deadline</li>
<li>prioritize it so that it can be started at that date, but not earlier</li>
<li>don&rsquo;t expect to be creating any value by completing these stories</li>
</ul>


<h2>What&rsquo;s the business value of other typical user stories</h2>

<p><a href="http://scaledagileframework.com/wsjf/">This article</a> suggests that in this case the cost of delay is equal to the business value of the feature for the user. But how can we have an idea of its actual user business value ?</p>

<p>Before actually selling and getting the money, it&rsquo;s just an estimation. With the good information, some people will make better estimates than others, never the less, it&rsquo;s still an estimate. Let&rsquo;s try a &ldquo;Business Value Poker&rdquo; ! Here are a few ideas about how to conduct this:</p>

<ul>
<li>Estimate business value at the same time as you estimate the complexity of a story</li>
<li>Create some business value $ poker estimate cards, write an app for this, or bring in some Poker Chips to estimate the value</li>
<li>Invite some business people (sales, marketting &hellip;) to the meeting to get real knowledge (being organized as a feature team will help)</li>
</ul>


<p><a href="https://gigaom.com/2012/05/16/social-gaming-to-gambling-states-inch-forward/poker-chips-by-sanzar-murzin/">{% img center /imgs/2014-10-16-how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/all-in.jpg &ldquo;Hands pushing poker chips for an all-in&rdquo; %}</a></p>

<p>At the end, when you have the estimated cost of delay and duration of every task, you can directly prioritize using the WSJF (Weighted Shortest Job First) :</p>

<blockquote><p>WSJF = Cost of Delay / Duration</p></blockquote>

<p>Just do the tasks by decreasing order of WSJF.</p>

<p>At the end of the sprint, just as we track the story points we completed with the velocity, we could track the business value we created, that would be our business value speed. If you have access to real sales numbers, it might be interesting to see if it&rsquo;s possible to correlate the figures.</p>

<h2>Afterthoughts</h2>

<p>The more I learn about Lean principles, the more I find our current Issues Tracking Systems (I&rsquo;m used to Jira) limited. They seem to be databases with a nice UI, whereas what we need are tools to help us to make better decisions out of the multitude of items &hellip; How come they do not provide something as simple as the WSJF ?</p>

<h2>Edit 12/09/2014</h2>

<p>I got some pretty positive feedback from practicing these business value pokers. Inviting the product owner forced him to explain in details why he believed some features were more valuable than others. On the opposite, it allowed the developpers to hightlight how some seemingly unimportant stories were critical to a long term goal. In the end, everyone, including the product owner, is asking for more. It&rsquo;s a good practice that helps introducing the business value / cost of delay concept.</p>

<p>This was part 3 of my <a href="/the-flow-book-summary-lean-software-development_part_1/">suite of article about Lean Software Development</a>, Part 2 was <a href="/why-extreme-programming-works-lean-software-development-part-2/">Why eXtreme Programming works ?</a>, Part 4 will be <a href="/measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/">Measure the business value of your spikes and take high payoff risks</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why eXtreme Programming works ? (Lean Software Development part 2)]]></title>
    <link href="http://philippe.bourgau.net/why-extreme-programming-works-lean-software-development-part-2/"/>
    <updated>2014-08-29T07:03:00+00:00</updated>
    <id>http://philippe.bourgau.net/why-extreme-programming-works-lean-software-development-part-2</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been programming for quite some time now, in different teams, using various methodologies. I also had the luck to do XP for at least 3 different projects. To me the conclusion is obvious, <a href="http://www.extremeprogramming.org/">XP</a> delivers more. Even better, programmers working with XP seem to be happier. The only thing I&rsquo;ve seen that works better than XP, is fine tunning it once the team has mastered the main principles.</p>

<p>{% img center /imgs/2014-09-11-whats-in-kent-becks-extreme-programming-lean-diet-lean-software-development-part-2/lean-extreme.jpg &ldquo;An extreme diet pill bottle&rdquo; %}</p>

<p><a href="http://en.wikipedia.org/wiki/Extreme_programming#History">XP was first put in place</a> at the Chrysler C3 project for SmallTalk performance issues. After being called for performance issues, <a href="http://www.threeriversinstitute.org/">Kent Beck</a> discovered that these were only the tip of the iceberg, everything was going astray. As the expert in the room, people started to ask him how to organize. I remember reading some time ago that without having thought about it before, he gathered all the most efficient programming techniques he knew together into a new process. XP was born.</p>

<p>So the question is : what did Kent Beck put in XP so that it works so well ? Let&rsquo;s go through the Flow book and its 175 lean product development principles, to see if we get some explanations.</p>

<p>{% img center /imgs/2014-09-11-whats-in-kent-becks-extreme-programming-lean-diet-lean-software-development-part-2/circles.jpg Concentric circles featuring the 12 core xp practices" %}</p>

<p>Going through <a href="http://c2.com/cgi/wiki?ExtremeProgrammingCorePractices">the 12 core XP practices</a>, the main Scrum ceremonies and a few common additions, I&rsquo;ll try to explain why they work through the Flow book&rsquo;s principles.</p>

<h2>Whole Team</h2>

<p>This is the same thing as Pizza Team, Feature team, Cross Functional Team. It just means put everyone involved in the creation of the product in the same room (On site customer, sales, product people, programmers, quality controllers, operation people &hellip;).</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>B17 </td>
<td> Proximity </td>
<td> Proximity enables small batch sizes </td>
<td> 129</td>
</tr>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>W13 </td>
<td> Skill overlap </td>
<td> Cross-train resources at adjacent processes </td>
<td> 156</td>
</tr>
<tr>
<td>F24 </td>
<td> Alternate routes </td>
<td> Develop and maintain alternate routes around points of congestion </td>
<td> 201</td>
</tr>
<tr>
<td>F25 </td>
<td> Flexible resources </td>
<td> Use flexible resources to absord variation </td>
<td> 202</td>
</tr>
<tr>
<td>FF14 </td>
<td> Locality of feedback </td>
<td> Whenever possible, make the feedback local </td>
<td> 226</td>
</tr>
<tr>
<td>FF19 </td>
<td> Colocation </td>
<td> Colocation improves almost all aspects of communication </td>
<td> 230</td>
</tr>
<tr>
<td>FF23 </td>
<td> Overlapping measurement </td>
<td> To align behaviors, reward people for the work of others </td>
<td> 233</td>
</tr>
<tr>
<td>D7 </td>
<td> Alignment </td>
<td> There is more value created with overall alignment than local execellence </td>
<td> 252</td>
</tr>
<tr>
<td>D13 </td>
<td> Peer-level coordination </td>
<td> Tactical coordination should be local </td>
<td> 257</td>
</tr>
<tr>
<td>D18 </td>
<td> Response frequency </td>
<td> We can&rsquo;t respond faster than our (internal) response frequency </td>
<td> 261</td>
</tr>
<tr>
<td>D22 </td>
<td> Face-to-face communication </td>
<td> Exploit the speed and bandwidth of face-to-face communications </td>
<td> 263</td>
</tr>
</tbody>
</table>


<h2>Planning Game</h2>

<p>The work is split into user stories. The customer then estimates the business value of each story, before the programmers poker estimate the required work for them. The game is then to maximize the scheduled business value creation for the coming iteration (1 to 3 weeks).</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>E4 </td>
<td> Economic value-added </td>
<td> The value added by an activity is the change in the economic value of the work product </td>
<td> 32</td>
</tr>
<tr>
<td>E7 </td>
<td> Imperfection </td>
<td> Even imperfect answers improve decision making </td>
<td> 36</td>
</tr>
<tr>
<td>E9 </td>
<td> Continuous economic tradeoffs </td>
<td> Economic choices must be made continuously </td>
<td> 37</td>
</tr>
<tr>
<td>E10 </td>
<td> Perishability I </td>
<td> Many economic choices are more valuable when made quickly </td>
<td> 38</td>
</tr>
<tr>
<td>E14 </td>
<td> Market I </td>
<td> Ensure decision makers feel both cost and benefit </td>
<td> 42</td>
</tr>
<tr>
<td>E15 </td>
<td> Optimium decision timing </td>
<td> Every decision has its optimum economic timing </td>
<td> 44</td>
</tr>
<tr>
<td>Q10 </td>
<td> Queueing discipline </td>
<td> Queue cost is affected by the sequence in which we handle the jobs in the queue </td>
<td> 69</td>
</tr>
<tr>
<td>Q13 </td>
<td> Queue size control I </td>
<td> Don&rsquo;t control capacity utilization, control queue size </td>
<td> 75</td>
</tr>
<tr>
<td>Q14 </td>
<td> Queue size control II </td>
<td> Don&rsquo;t control the cycle time, control queue size </td>
<td> 76</td>
</tr>
<tr>
<td>V5 </td>
<td> Variability pooling </td>
<td> Overall variation decreases when uncorrelated random tasks are combined </td>
<td> 95</td>
</tr>
<tr>
<td>V6 </td>
<td> Short-term forcasting </td>
<td> Forecasting becomes exponentially easier at short time-horizons </td>
<td> 96</td>
</tr>
<tr>
<td>B18 </td>
<td> Run length </td>
<td> Short run lengths reduce queues </td>
<td> 130</td>
</tr>
<tr>
<td>B20 </td>
<td> Batch content </td>
<td> Sequence first that which adds value most cheaply </td>
<td> 131</td>
</tr>
<tr>
<td>W1 </td>
<td> WIP constraints </td>
<td> Constrain WIP to control cycle time and flow </td>
<td> 145</td>
</tr>
<tr>
<td>W3 </td>
<td>  global constraints  </td>
<td> Use global constraints for predictable and permanent bottlenecks </td>
<td> 147</td>
</tr>
<tr>
<td>W6 </td>
<td> Demand blocking </td>
<td> Block all demand when WIP reaches its upper limit </td>
<td> 151</td>
</tr>
<tr>
<td>W8 </td>
<td> Flexible requirements </td>
<td> Control WIP by shedding requirements </td>
<td> 152</td>
</tr>
<tr>
<td>W19 </td>
<td> Adaptive WIP constraints </td>
<td> Adjust WIP constraints as capacity changes </td>
<td> 162</td>
</tr>
<tr>
<td>F5 </td>
<td> Periodic resynchronization </td>
<td> Use a regular cadence to limit the accumulation of variance </td>
<td> 177</td>
</tr>
<tr>
<td>F7 </td>
<td> The cadence reliability </td>
<td> Use cadence to make waiting times predictable </td>
<td> 179</td>
</tr>
<tr>
<td>F9 </td>
<td> Cadenced meetings </td>
<td> Schedule frequent meetings using a predictable cadence </td>
<td> 180</td>
</tr>
<tr>
<td>F18 </td>
<td> The local priority </td>
<td> Priorities are inherently local </td>
<td> 196</td>
</tr>
<tr>
<td>FF10 </td>
<td> Agility I </td>
<td> We don&rsquo;t need long planning horizons when we have a short turning radius </td>
<td> 222</td>
</tr>
<tr>
<td>FF21 </td>
<td> Hurry-up-and-wait </td>
<td> Large queues make it hard to create urgency </td>
<td> 232</td>
</tr>
<tr>
<td>D4 </td>
<td> Opportunity </td>
<td> Adjust the plan for unplanned obstacles and opportunities </td>
<td> 249</td>
</tr>
<tr>
<td>D14 </td>
<td> Flexible plans </td>
<td> Use simple modular plans </td>
<td> 258</td>
</tr>
</tbody>
</table>


<h2>Small Releases</h2>

<p>Make a lot of small releases.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q2 </td>
<td> Queueing waste </td>
<td> Queues are the root cause of the majority of economic waste in product development </td>
<td> 56</td>
</tr>
<tr>
<td>V8 </td>
<td> Repetition </td>
<td> Repetition reduces variation </td>
<td> 99</td>
</tr>
<tr>
<td>B1-8 </td>
<td> Batch size </td>
<td> Reducing batch size reduces cycle time, variability in flow, risk, overhead and accelerates feedback, while large batches reduces efficiency, lower motivation and urgency and cause exponential cost and schedule growth  </td>
<td> 112-117</td>
</tr>
<tr>
<td>F8 </td>
<td> Cadenced batch size enabling </td>
<td> Use a regular cadence to enable small batch size </td>
<td> 179</td>
</tr>
<tr>
<td>FF7 </td>
<td> Queue reduction by feedback </td>
<td> Fast feedback enables smaller queues </td>
<td> 220</td>
</tr>
<tr>
<td>FF8 </td>
<td> Fast-learning </td>
<td> Use fast feedback to make learning faster and more efficient </td>
<td> 220</td>
</tr>
<tr>
<td>FF11 </td>
<td> Batch size feedback </td>
<td> Small batches yield fast feedback </td>
<td> 223</td>
</tr>
<tr>
<td>FF20 </td>
<td> Empowerment by feedback </td>
<td> Fast feedback gives a sense of control </td>
<td> 231</td>
</tr>
<tr>
<td>FF21 </td>
<td> Hurry-up-and-wait </td>
<td> Large queues make it hard to create urgency </td>
<td> 232</td>
</tr>
<tr>
<td>D23 </td>
<td> Trust </td>
<td> Trust is built through experience </td>
<td> 264</td>
</tr>
</tbody>
</table>


<h2>Customer Tests</h2>

<p>The customer assists the programmers into writing automated use case tests.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>V16 </td>
<td> Variability displacements </td>
<td> Move variability to the process stage where its cost is lowest </td>
<td> 107</td>
</tr>
<tr>
<td>B17 </td>
<td> Proximity </td>
<td> Proximity enables small batch sizes </td>
<td> 129</td>
</tr>
<tr>
<td>F30 </td>
<td> Flow conditioning </td>
<td> Reduce variability before a bottleneck </td>
<td> 208</td>
</tr>
<tr>
<td>FF7 </td>
<td> Queue reduction by feedback </td>
<td> Fast feedback enables smaller queues </td>
<td> 220</td>
</tr>
<tr>
<td>FF8 </td>
<td> Fast-learning </td>
<td> Use fast feedback to make learning faster and more efficient </td>
<td> 220</td>
</tr>
<tr>
<td>FF11 </td>
<td> Batch size feedback </td>
<td> Small batches yield fast feedback </td>
<td> 223</td>
</tr>
<tr>
<td>FF14 </td>
<td> Locality of feedback </td>
<td> Whenever possible, make the feedback local </td>
<td> 226</td>
</tr>
<tr>
<td>FF19 </td>
<td> Colocation </td>
<td> Colocation improves almost all aspects of communication </td>
<td> 230</td>
</tr>
<tr>
<td>FF20 </td>
<td> Empowerment by feedback </td>
<td> Fast feedback gives a sense of control </td>
<td> 231</td>
</tr>
<tr>
<td>D8 </td>
<td> Mission </td>
<td> Specify the end state, its purpose and the minimum possible constraints </td>
<td> 252</td>
</tr>
<tr>
<td>D16 </td>
<td> Early contact </td>
<td> Make early and meaningful contact with the problem </td>
<td> 259</td>
</tr>
</tbody>
</table>


<h2>Collective Code Ownership</h2>

<p>Every programmer is responsible to evolve and maintain all the source code, and not just his part.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q7 </td>
<td> Queuing structure </td>
<td> Serve pooled demand with reliable high-capacity servers </td>
<td> 64</td>
</tr>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>F25 </td>
<td> Flexible resources </td>
<td> Use flexible resources to absord variation </td>
<td> 202</td>
</tr>
<tr>
<td>FF23 </td>
<td> Overlapping measurement </td>
<td> To align behaviors, reward people for the work of others </td>
<td> 233</td>
</tr>
<tr>
<td>D1 </td>
<td> Perishablility II </td>
<td> Decentralize control for problems and opportunities that age poorly </td>
<td> 246</td>
</tr>
<tr>
<td>D4 </td>
<td> Virtual centralization </td>
<td> Be able to quickly reorganize decentralized resources to create centralized power </td>
<td> 250</td>
</tr>
<tr>
<td>D5 </td>
<td> Inefficiency </td>
<td> The inefficiency of decentralization (as opposed to silos) can cost less than the value of faster reponse time </td>
<td> 251</td>
</tr>
</tbody>
</table>


<h2>Coding Standards</h2>

<p>All programmers agree on coding conventions for all the source code they write.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>F25 </td>
<td> Flexible resources </td>
<td> Use flexible resources to absord variation </td>
<td> 202</td>
</tr>
</tbody>
</table>


<h2>Sustainable Pace</h2>

<p>As the value created by a knowledge work does not increase linearly with the time spent, it&rsquo;s wiser to work a number of hours that both maximizes the work done while allowing the team to keep on going forever if needed.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>E5 </td>
<td> Inactivity </td>
<td> Watch the work product, not the worker </td>
<td> 33</td>
</tr>
<tr>
<td>Q3 </td>
<td> Queueing capacity utilization </td>
<td> Capacity utilization increases queues exponentially </td>
<td> 59</td>
</tr>
<tr>
<td>B9 </td>
<td> Batch size death spiral </td>
<td> Large batches lead to even large batches </td>
<td> 118</td>
</tr>
</tbody>
</table>


<h2>Metaphor</h2>

<p>Whether an actual metaphor or an ubiquitous language, the idea is to build a shared customer oriented architecture and design of the system.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>F25 </td>
<td> Flexible resources </td>
<td> Use flexible resources to absord variation </td>
<td> 202</td>
</tr>
</tbody>
</table>


<h2>Continuous Integration</h2>

<p>All the code of all the team is merged, tested, packaged and deployed very frequently (many times per day)</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q2 </td>
<td> Queueing waste </td>
<td> Queues are the root cause of the majority fo economic waste in product development </td>
<td> 56</td>
</tr>
<tr>
<td>V8 </td>
<td> Repetition </td>
<td> Repetition reduces variation </td>
<td> 99</td>
</tr>
<tr>
<td>B1-8 </td>
<td> Batch size </td>
<td> Reducing batch size reduces cycle time, variability in flow, risk, overhead and accelerates feedback, while large batches reduces efficiency, lower motivation and urgency and cause exponential cost and schedule growth  </td>
<td> 112-117</td>
</tr>
<tr>
<td>B12 </td>
<td> Low transaction cost </td>
<td> Reducing the transaction cost per batch lowers overall costs </td>
<td> 123</td>
</tr>
<tr>
<td>B16 </td>
<td> Transport batches </td>
<td> The most important batch is the transport batch </td>
<td> 128</td>
</tr>
<tr>
<td>B19 </td>
<td> Infrastructure </td>
<td> Good infrastructure enables small batches </td>
<td> 130</td>
</tr>
<tr>
<td>F29 </td>
<td> Resource centralization </td>
<td> Correctly managed, centralized resources can reduce queues </td>
<td> 206</td>
</tr>
<tr>
<td>FF7 </td>
<td> Queue reduction by feedback </td>
<td> Fast feedback enables smaller queues </td>
<td> 220</td>
</tr>
<tr>
<td>FF11 </td>
<td> Batch size feedback </td>
<td> Small batches yield fast feedback </td>
<td> 223</td>
</tr>
<tr>
<td>FF16 </td>
<td> Multiple control loops </td>
<td> Embed fast control loops inside slow loops </td>
<td> 228</td>
</tr>
<tr>
<td>FF21 </td>
<td> Hurry-up-and-wait </td>
<td> Large queues make it hard to create urgency </td>
<td> 232</td>
</tr>
</tbody>
</table>


<h2>Test Driven Development</h2>

<p>Programmers write failing tests (both customer and unit tests) before actual real code</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>V15 </td>
<td> Iteration speed </td>
<td> it is usually better to improve iteration speed than defect rate </td>
<td> 106</td>
</tr>
<tr>
<td>V16 </td>
<td> Variability displacements </td>
<td> move variability to the process stage where its cost is lowest </td>
<td> 107</td>
</tr>
<tr>
<td>B1-8 </td>
<td> Batch size </td>
<td> Reducing batch size reduces cycle time, variability in flow, risk, overhead and accelerates feedback, while large batches reduces efficiency, lower motivation and urgency and cause exponential cost and schedule growth  </td>
<td> 112-117</td>
</tr>
<tr>
<td>F30 </td>
<td> Flow conditioning </td>
<td> Reduce variability before a bottleneck </td>
<td> 208</td>
</tr>
<tr>
<td>FF7 </td>
<td> Queue reduction by feedback </td>
<td> Fast feedback enables smaller queues </td>
<td> 220</td>
</tr>
<tr>
<td>FF8 </td>
<td> The fast-learning principle </td>
<td> Use fast feedback to make learning faster and more efficient </td>
<td> 220</td>
</tr>
<tr>
<td>FF11 </td>
<td> The batch size principle of feedback </td>
<td> Small batches yield fast feedback </td>
<td> 223</td>
</tr>
<tr>
<td>FF14 </td>
<td> The locality principle of feedback </td>
<td> Whenever possible, make the feedback local </td>
<td> 226</td>
</tr>
<tr>
<td>FF16 </td>
<td> The principle of multiple control loops </td>
<td> Embed fast control loops inside slow loops </td>
<td> 228</td>
</tr>
<tr>
<td>FF20 </td>
<td> The empowerment principle of feedback </td>
<td> Fast feedback gives a sense of control </td>
<td> 231</td>
</tr>
</tbody>
</table>


<h2>Refactoring</h2>

<p>Programmers improve the design of the system continuously, meaning in very frequent baby steps. This removes the need for a big design up front.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>E13 </td>
<td> The first decision rule principle </td>
<td> Use decision rules to decentralize economic control </td>
<td> 41</td>
</tr>
<tr>
<td>V9 </td>
<td> The reuse principle </td>
<td> Reuse reduces variability </td>
<td> 100</td>
</tr>
<tr>
<td>B9 </td>
<td> The batch size death spiral principle </td>
<td> Large batches lead to even large batches </td>
<td> 118</td>
</tr>
<tr>
<td>B19 </td>
<td> The infrastructure principle </td>
<td> Good infrastructure enables small batches </td>
<td> 130</td>
</tr>
<tr>
<td>F28 </td>
<td> The principle of preplanned flexibility </td>
<td> For fast responses, preplan and invest in flexibility </td>
<td> 205</td>
</tr>
<tr>
<td>D12 </td>
<td> The second agility principle </td>
<td> Develop the ability to quickly shift focus </td>
<td> 255</td>
</tr>
</tbody>
</table>


<h2>Simple Design</h2>

<p>Do the simplest thing that could possibly work. No need to write things that don&rsquo;t add business value yet. (Note that simple does not mean easy)</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>E19 </td>
<td> Insurance </td>
<td> Don&rsquo;t pay more for insurance than the expected loss </td>
<td> 49</td>
</tr>
<tr>
<td>V12 </td>
<td> Variability consequences </td>
<td> Reducing consequences is usually the best way to reduce the cost of variability </td>
<td> 103</td>
</tr>
<tr>
<td>B9 </td>
<td> Batch size death spiral </td>
<td> Large batches lead to even large batches </td>
<td> 118</td>
</tr>
<tr>
<td>B15 </td>
<td> Fluidity </td>
<td> Loose coupling between product subsystems enables small batches </td>
<td> 126</td>
</tr>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>F25 </td>
<td> Flexible resources </td>
<td> Use flexible resources to absorb variation </td>
<td> 202</td>
</tr>
<tr>
<td>D12 </td>
<td> Agility II </td>
<td> Develop the ability to quickly shift focus </td>
<td> 255</td>
</tr>
</tbody>
</table>


<h2>Pair Programming</h2>

<p>Programmers sit at the same computer in pairs to write code. One write the code, and the other comments. The keyboard changes hands very frequently.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>B13 </td>
<td> Batch size diseconomies </td>
<td> Batch size reduction saves much more than you think </td>
<td> 124</td>
</tr>
<tr>
<td>B21 </td>
<td> Batch size I </td>
<td> Reduce the batch size before you attack bottlenecks </td>
<td> 133</td>
</tr>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>W13 </td>
<td> Skill overlap </td>
<td> Cross-train resources at adjacent processes </td>
<td> 156</td>
</tr>
<tr>
<td>F25 </td>
<td> Flexible resources </td>
<td> Use flexible resources to absord variation </td>
<td> 202</td>
</tr>
<tr>
<td>F30 </td>
<td> Flow conditioning </td>
<td> Reduce variability before a bottleneck </td>
<td> 208</td>
</tr>
<tr>
<td>FF14 </td>
<td> Locality of feedback </td>
<td> Whenever possible, make the feedback local </td>
<td> 226</td>
</tr>
<tr>
<td>FF16 </td>
<td> Multiple control loops </td>
<td> Embed fast control loops inside slow loops </td>
<td> 228</td>
</tr>
<tr>
<td>FF19 </td>
<td> Colocation </td>
<td> Colocation improves almost all aspects of communication </td>
<td> 230</td>
</tr>
<tr>
<td>FF20 </td>
<td> Empowerment by feedback </td>
<td> Fast feedback gives a sense of control </td>
<td> 231</td>
</tr>
<tr>
<td>D13 </td>
<td> Peer-level coordination </td>
<td> Tactical coordination should be local </td>
<td> 257</td>
</tr>
<tr>
<td>D22 </td>
<td> Face-to-face communication </td>
<td> Exploit the speed and bandwidth of face-to-face communications </td>
<td> 263</td>
</tr>
</tbody>
</table>


<h2>Spikes</h2>

<p>Programmers conduct time boxed experiment to gain insights</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>V2 </td>
<td> Asymmetric payoffs </td>
<td> Payoff asymmetries enable variability to create economic value </td>
<td> 88</td>
</tr>
<tr>
<td>V7 </td>
<td> Small experiments </td>
<td> Many small experiments produce less variation than one big one </td>
<td> 98</td>
</tr>
</tbody>
</table>


<h2>Slack Time</h2>

<p>Keep some buffer time at the end of the iteration where team members can either close the remaining stories or work on improvements.</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>V11 </td>
<td> Buffer </td>
<td> Buffers trade money for variability reduction </td>
<td> 101</td>
</tr>
<tr>
<td>B9 </td>
<td> Batch size death spiral </td>
<td> Large batches lead to even large batches </td>
<td> 118</td>
</tr>
<tr>
<td>B19 </td>
<td> Infrastructure </td>
<td> Good infrastructure enables small batches </td>
<td> 130</td>
</tr>
<tr>
<td>F6 </td>
<td> Ccadence capacity margin </td>
<td> Provide sufficient capacity margin to enable cadence </td>
<td> 178</td>
</tr>
<tr>
<td>D12 </td>
<td> Agility II </td>
<td> Develop the ability to quickly shift focus </td>
<td> 255</td>
</tr>
<tr>
<td>D15 </td>
<td> Tactical reserves </td>
<td> Decentralize a portion of reserves </td>
<td> 258</td>
</tr>
</tbody>
</table>


<h2>Daily Stand Up Meeting</h2>

<p>The whole team starts every working day by a quick synchronization meeting</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>B3 </td>
<td> Batch size feedback </td>
<td> Reducing batch size accelerate feedback </td>
<td> 113</td>
</tr>
<tr>
<td>W12 </td>
<td> T-Shaped resources </td>
<td> Develop people who are deep in one area and broad in many </td>
<td> 155</td>
</tr>
<tr>
<td>W20 </td>
<td> Expansion control </td>
<td> Prevent uncontrolled expansion of work </td>
<td> 163</td>
</tr>
<tr>
<td>F5 </td>
<td> Periodic resynchronization </td>
<td> Use a regular cadence to limit the accumulation of variance </td>
<td> 177</td>
</tr>
<tr>
<td>F9 </td>
<td> Cadenced meetings </td>
<td> Schedule frequent meetings using a predictable cadence </td>
<td> 180</td>
</tr>
</tbody>
</table>


<h2>Retrospective meeting</h2>

<p>At the end of every iteration, the team meets for a retrospective, discussing what they did in order to improve</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>B9 </td>
<td> Batch size death spiral </td>
<td> Large batches lead to even large batches </td>
<td> 118</td>
</tr>
<tr>
<td>B19 </td>
<td> Infrastructure </td>
<td> Good infrastructure enables small batches </td>
<td> 130</td>
</tr>
<tr>
<td>F9 </td>
<td> Cadenced meetings </td>
<td> Schedule frequent meetings using a predictable cadence </td>
<td> 180</td>
</tr>
<tr>
<td>FF8 </td>
<td> Fast-learning </td>
<td> Use fast feedback to make learning faster and more efficient </td>
<td> 220</td>
</tr>
<tr>
<td>FF20 </td>
<td> Empowerment by feedback </td>
<td> Fast feedback gives a sense of control </td>
<td> 231</td>
</tr>
<tr>
<td>D21 </td>
<td> Regenerative initiative </td>
<td> Cultivating initiative enables us to use initiative </td>
<td> 263</td>
</tr>
</tbody>
</table>


<h2>Demos</h2>

<p>At the end of every iteration, the team demonstrates what it did to the customer</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>E14 </td>
<td> Market I </td>
<td> Ensure decision makers feel both cost and benefit </td>
<td> 42</td>
</tr>
<tr>
<td>B3 </td>
<td> Batch size feedback </td>
<td> Reducing batch size accelerate feedback </td>
<td> 113</td>
</tr>
<tr>
<td>B9 </td>
<td> Batch size death spiral </td>
<td> Large batches lead to even large batches </td>
<td> 118</td>
</tr>
<tr>
<td>F9 </td>
<td> Cadenced meetings </td>
<td> Schedule frequent meetings using a predictable cadence </td>
<td> 180</td>
</tr>
<tr>
<td>FF7 </td>
<td> Queue reduction by feedback </td>
<td> Fast feedback enables smaller queues </td>
<td> 220</td>
</tr>
<tr>
<td>FF8 </td>
<td> Fast-learning </td>
<td> Use fast feedback to make learning faster and more efficient </td>
<td> 220</td>
</tr>
<tr>
<td>FF20 </td>
<td> Empowerment by feedback </td>
<td> Fast feedback gives a sense of control </td>
<td> 231</td>
</tr>
<tr>
<td>FF21 </td>
<td> Hurry-up-and-wait </td>
<td> Large queues make it hard to create urgency </td>
<td> 232</td>
</tr>
<tr>
<td>FF23 </td>
<td> Overlapping measurement </td>
<td> To align behaviors, reward people for the work of others </td>
<td> 233</td>
</tr>
<tr>
<td>D23 </td>
<td> Trust </td>
<td> Trust is built through experience </td>
<td> 264</td>
</tr>
</tbody>
</table>


<h2>Visual Whiteboard</h2>

<p>Display the stories of the current sprint on the wall in a 3 columns whiteboard (TODO, DOING, DONE)</p>

<table>
<thead>
<tr>
<th>Ref </th>
<th> The principle of &hellip; </th>
<th> Summary </th>
<th> page</th>
</tr>
</thead>
<tbody>
<tr>
<td>W23 </td>
<td> Visual WIP </td>
<td> Make WIP continuously visible </td>
<td> 166</td>
</tr>
<tr>
<td>F27 </td>
<td> Local transparency </td>
<td> Make tasks and resources reciprocally visible at adjacent processes </td>
<td> 204</td>
</tr>
<tr>
<td>D17 </td>
<td> Decentralized information </td>
<td> For decentralized decisions, disseminate key information widely </td>
<td> 260</td>
</tr>
</tbody>
</table>


<h2>Conclusion</h2>

<p>Whaoo that&rsquo;s a lot ! I did not expect to find so many principles underlying XP (I even removed principles that were not self explanatory). For the XP practitioner that I am, writing this blog post helped me to deepen understanding of it. As XPers know, XP is quite opiniated, it&rsquo;s both a strength and a weakness if you try to apply it outside of its zone of comfort. This explains why some lean subjects are simply not addressed by XP.</p>

<p>To summarize, here is where XP hits the ground :</p>

<ul>
<li>In spite of its image of &lsquo;a process for nerdy programmers&rsquo; XP turns out to be a quite evolved lean method !</li>
<li>XP anihilates batch size and feedback time</li>
<li>Pair programming is well explained</li>
</ul>


<p>And here is where to look at when you&rsquo;ll need to upgrade XP</p>

<ul>
<li>Better tradeoffs might be found with a real quantitative economical framework</li>
<li>Synchronization principles might help working with other teams</li>
</ul>


<p>Kent Beck could not have read the Flow book when he invented XP, but it seems he just had a bit of advance on the rest of us &hellip;</p>

<p>This was part 2 of my <a href="/the-flow-book-summary-lean-software-development_part_1/">suite of article about Lean Software Development</a>, Part 1 was <a href="/the-flow-book-summary-lean-software-development_part_1/">The Flow book summary</a>, Part 3 will be <a href="/how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/">How to measure your speed with your business value ?</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Flow book summary (lean software development part 1)]]></title>
    <link href="http://philippe.bourgau.net/the-flow-book-summary-lean-software-development_part_1/"/>
    <updated>2014-08-29T06:25:00+00:00</updated>
    <id>http://philippe.bourgau.net/the-flow-book-summary-lean-software-development_part_1</id>
    <content type="html"><![CDATA[<p>A few weeks ago, I read <a href="http://www.amazon.com/The-Principles-Product-Development-Flow/dp/1935401009">The principles of product development flow</a> from Donald G. Reinertsen.</p>

<p>{% img center /imgs/2014-08-29-the-flow-book-summary-lean-software-development_part_1/flow_book_cover.jpg The cover of the book %}</p>

<p>I read it both for work and for my side projects, and I think it will be useful for both. The book is about lean product development, and is in fact a collection of 175 lean principles that one can study and understand in order to make better decisions when developing new products. The principles are divided into the following 8 categories</p>

<ol>
<li>Economics</li>
<li>Queues</li>
<li>Variability</li>
<li>Batch sise</li>
<li>WIP constraints</li>
<li>Cadence, synchronization and flow control</li>
<li>Fast feedback</li>
<li>Decentralized control</li>
</ol>


<p>I really loved the book. I have not been thrilled like that by a book since <a href="http://www.threeriversinstitute.org/">Kent Beck</a>&rsquo;s <a href="http://www.amazon.com/Extreme-Programming-Explained-Embrace-Change/dp/0201616416">1st edition of Extreme Programming Explained</a>. Where Kent Beck described some values, principles and practices that work. D.G. Reinertsen has the ambition to help us to quantify these practices in order not move from belief based to fact based decisions. For this, he gives us the keys to creating an economical framework with which we should be able to convert any change option to its economical cost</p>

<p>{% img center /imgs/2014-08-29-the-flow-book-summary-lean-software-development_part_1/xp_book_cover.jpg The cover of the book &ldquo;Extreme Programming Explained&rdquo; %}</p>

<p>Lately, I&rsquo;ve been thinking of an economical framework of my own, that I could use on the projects I am currently involved in. This post is the first of a series about this :</p>

<ol>
<li><a href="/the-flow-book-summary-lean-software-development_part_1">The Flow book summary</a></li>
<li><a href="/why-extreme-programming-works-lean-software-development-part-2/">Why eXtreme Programming works ?</a></li>
<li><a href="/how-to-measure-your-speed-with-your-business-value-lean-software-development-part-3/">How to measure your speed with your business value ?</a></li>
<li><a href="/measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/">Measure the business value of your spikes and take high payoff risks</a></li>
<li><a href="/what-optimization-should-we-work-on-lean-software-development-part-5/">What optimization should we work on ?</a></li>
<li>Measure the value of the lean startup &lsquo;learning&rsquo;</li>
<li>Prioritizing technical improvements</li>
<li>Summing it up for my next side project</li>
</ol>


<p>Next part will feature an explanation of the XP practices with the lean principles. Stay tuned.</p>
]]></content>
  </entry>
  
</feed>
