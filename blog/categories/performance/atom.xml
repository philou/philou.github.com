<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: performance | Philippe Bourgau's blog]]></title>
  <link href="http://philippe.bourgau.net/blog/categories/performance/atom.xml" rel="self"/>
  <link href="http://philippe.bourgau.net/"/>
  <updated>2018-06-27T19:18:12+02:00</updated>
  <id>http://philippe.bourgau.net/</id>
  <author>
    <name><![CDATA[Philippe Bourgau]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Verify the Big O Complexity of Ruby Code in RSpec]]></title>
    <link href="http://philippe.bourgau.net/verify-the-big-o-complexity-of-ruby-code-in-rspec/"/>
    <updated>2017-01-04T17:48:00+01:00</updated>
    <id>http://philippe.bourgau.net/verify-the-big-o-complexity-of-ruby-code-in-rspec</id>
    <content type="html"><![CDATA[<p>It might be possible to discover performance regressions before running your long and large scale benchmarks !</p>

<p><a href="https://github.com/philou/complexity-assert">complexity_assert</a> is an <a href="http://rspec.info/">RSpec</a> library that determines and checks the <a href="http://bigocheatsheet.com/">big O complexity</a> of a piece of code. Once you&rsquo;ve determined the performance critical sections of your system, you can use it to verify that they perform with the complexity you expect.</p>

<h2>How does it work ?</h2>

<p>The gem itself is the result of an experiment to learn machine learning in 20 hours (you can read more about that experiment in <a href="/how-i-got-my-feet-wet-with-machine-learning-with-the-first-20-hours/">my previous post</a> if you want).</p>

<p>Suppose you have some a method, let&rsquo;s call it <code>match_products_with_orders(products, orders)</code> which is called in in one of your processes with very large arguments. Badly written, this method could be quadratic (O(n²)), which would lead to catastrophic performances in production. When coding it, you&rsquo;ve taken particular care to make it perform in linear time. Unfortunately, it could easily slip back to a slower implementation with a bad refactoring &hellip; Using complexity_assert, you can make sure that this does not happen :</p>

<p>``` ruby</p>

<h1>An adapter class to fit the code to measure in complexity assert</h1>

<p>class ProductsOrdersMatching</p>

<pre><code># Generate some arguments of a particular size
def generate_args(size)
    # Let's assume we have 10 times less products than orders
    [ Array.new(size / 10) { build_a_product() }, Array.new(size) { build_an_order() } ]
end

# Run the code on which we want to assert performance
def run(products, orders)
    match_products_with_orders(products, orders)
end
</code></pre>

<p>end</p>

<p>describe &ldquo;Products and Orders Matching&rdquo; do</p>

<pre><code>it "performs linearly" do
    # Verify that the code runs in time proportional to the size of its arguments
    expect(ProductOrdersMatching.new).to be_linear()
end
</code></pre>

<p>end
```</p>

<p>That&rsquo;s it ! If ever someone changes the code of <code>match_products_with_orders</code> and makes it perform worse than linearly, the assertion will fail ! There are similar assertions to check for constant and quadratic execution times.</p>

<p>Internally, the code will be called a number of times with different (smallish) sizes of arguments and the execution times will be logged. When this is over, by doing different flavors of linear regressions, it should determine whether the algorithm performs in O(1), O(n) or O(n²). Depending on your code, this can take time to run, but should still be faster than running large scale benchmarks.</p>

<p>Just check the <a href="https://github.com/philou/complexity-assert/blob/master/README.md">README</a> for more details.</p>

<h2>Did you say experiment ?</h2>

<p>It all started like an experiment. So the gem itself, is still experimental ! It&rsquo;s all fresh, and it could receive a lot of enhancements like :</p>

<ul>
<li>Allow the assertion to specify the sizes</li>
<li>Allow the assertion to specify the warm-up and run rounds</li>
<li>Robustness against garbage collection : use GC intensive ruby methods, and see how the regression behaves</li>
<li>Find ways to make the whole thing faster</li>
<li>O(lnx) : pre-treat with exp()</li>
<li>O(?lnx) : use exp, then a search for the coefficient (aka polynomial)</li>
<li>O(xlnx) : there is no well known inverse for that, we can compute it numerically though</li>
<li>Estimate how much the assert is deterministic</li>
<li>&hellip;</li>
</ul>


<p>As you see, there&rsquo;s a lot of room for ideas and improvements.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[3 More Great Talks From JavaOne 2016]]></title>
    <link href="http://philippe.bourgau.net/3-more-great-talks-from-javaone-2016/"/>
    <updated>2016-10-14T04:05:00+02:00</updated>
    <id>http://philippe.bourgau.net/3-more-great-talks-from-javaone-2016</id>
    <content type="html"><![CDATA[<p>After the top <a href="/top-5-talks-i-attented-at-java-one-2016-part-1/">5 talks I attended at JavaOne</a> here are more !</p>

<h2>Managing Open Source Contributions in Large Organizations</h2>

<p><a href="http://www.jamesward.com/presos">James Ward</a></p>

<p>This talk was very interesting for companies or organizations that want to use Open Source in some way without ignoring the risks.</p>

<p>After an introduction listing the benefits of contributing to open source, James explained the associated risks :</p>

<ul>
<li>Security (evil contributions or information leaks)</li>
<li>Quality (bad contributions, increased maintenance or showing a bad image)</li>
<li>Legal (responsibility in case of patent infringing contribution, ownership of a contribution, licenses)</li>
</ul>


<p>He then explained that there are 3 ways to deal with the issue :</p>

<table>
<thead>
<tr>
<th> Strategy </th>
<th> Description </th>
<th> Pros </th>
<th> Cons </th>
<th> Popularity </th>
<th> Examples </th>
</tr>
</thead>
<tbody>
<tr>
<td> Do nothing </td>
<td> Devs just contribute without saying it </td>
<td> Easy, Gets it done </td>
<td> Need to stay under the radar, Risks for all parties are ignores </td>
<td> +++++ </td>
<td> Most open source code on <a href="https://github.com">Github</a> is shared in this manner |</td>
</tr>
<tr>
<td> Join a foundation </td>
<td> Joining an existing open source foundation, with a framework </td>
<td> Everything out of the box (infra, governance), builds trust </td>
<td> Rules can be heavy, Ownership is given to the foundation </td>
<td> +++ </td>
<td> <a href="https://www.linkedin.com/">Linkedin</a> put <a href="https://kafka.apache.org/">Kafka</a> in the <a href="https://www.apache.org/">Apache Foundation</a> |</td>
</tr>
<tr>
<td> Build tools </td>
<td> Use your own tools to mitigate the main risks associated with the &lsquo;Do nothing&rsquo; strategy </td>
<td> Built on top of Github, Keep control, Keeps things easy </td>
<td> Need to develop, test and operate the tools </td>
<td> + </td>
<td> Demo of a tool plugged into Github to enforce a contributor license agreement for anyone pushing a pull request |</td>
</tr>
</tbody>
</table>


<p><a href="/imgs/2016-10-14-3-more-great-talks-from-javaone-2016/CLA.jpg"><img class="center" src="/imgs/2016-10-14-3-more-great-talks-from-javaone-2016/CLA-small.jpg" title="Slide with a Github capture for Contributor License Agreement" ></a></p>

<p>The &lsquo;build tools&rsquo; strategy looks promising, even if it is not yet widely used !</p>

<p>Here are <a href="https://www.youtube.com/watch?v=X71HrW6vC_0">the talk</a> and <a href="http://presos.jamesward.com/managing_open_source_contributions_in_large_orgs/index.html#/">the slides</a> on the authors website.</p>

<h2>Java Performance Analysis in Linux with Flame Graphs</h2>

<p><a href="http://www.brendangregg.com/">Brendan Gregg</a></p>

<p>This is what a flame graph looks like :</p>

<p><a href="http://www.brendangregg.com/FlameGraphs/cpu-mixedmode-vertx.svg"><img class="center" src="/imgs/2016-10-14-3-more-great-talks-from-javaone-2016/flamegraph.png" title="An example of a Java flame graph" ></a></p>

<p>Technically, it&rsquo;s just an SVG with some Javascript. It shows the performance big picture. It aggregates data from Linux and JVM profilers. Vertically, you can see the call stacks in your system. The larger a block, the more time is taken inside a function (or in a sub call). The top border is where the CPU time is actually taken. If you want to speed up your system, speed up the wider zones at the top of the graph.</p>

<p>At <a href="https://www.netflix.com">Netflix</a>, the speaker is a performance engineer, and his job is to build tools to help other teams discover performance issues. This is how they use Flame Graphs :</p>

<ul>
<li>Compare 2 flame graphs at different times to see what changed</li>
<li>Do a <a href="http://martinfowler.com/bliki/CanaryRelease.html">canary release</a> and compare the new flame graph before finishing the deployment</li>
<li>Taking continuous flame graphs on running services helps identify JVM behavior like JIT or GC</li>
<li>They use different color themes to highlight different things</li>
<li>They also use them to identify CPU cache misses</li>
</ul>


<p>By the way, I also thought this was a great example of using an innovative visualization to manage tons of data.</p>

<p>I could find neither the video nor the slides of the talk, but I managed to find a lot of <a href="https://www.google.fr/search?safe=active&amp;client=ubuntu&amp;espv=2&amp;biw=1600&amp;bih=810&amp;tbm=vid&amp;q=Flame+Graphs&amp;oq=Flame+Graphs&amp;gs_l=serp.3...1396.1396.0.1616.1.1.0.0.0.0.59.59.1.1.0....0...1c.1.64.serp..0.0.0.z-3ygDHx4-Q">others talks about Flame Graphs</a>, as well as extra material on <a href="http://www.brendangregg.com/flamegraphs.html">the speaker&rsquo;s homepage</a>.</p>

<h2>Increasing Code Quality with Gamification</h2>

<p><a href="https://twitter.com/alex90_ch">Alexander Chatzizacharias</a></p>

<p>You might be wondering why we should care about gamification ?</p>

<ul>
<li>Worldwide 11.2 billion hours are spent playing every week !</li>
<li>People love to play because it makes them feel awesome</li>
<li>Games are good teachers</li>
<li>At work we are the ones who need to make others successful</li>
<li>But only 32% of workers are engaged in their work !</li>
</ul>


<p>Games rely on 4 main dynamics :</p>

<ul>
<li>Competition (be very careful of closed economics which can be very bad for teams)</li>
<li>Peer pressure (Public stats push teams and individual to conform to the norm)</li>
<li>Progression (regular recognition of new skills is motivating)</li>
<li>Rewards (Badges, Level ups, Monkey Money, real money &hellip;)</li>
</ul>


<p>He went on to demonstrate two games that are based on Jenkins and Sonar that aim at better code quality :</p>

<ul>
<li>One mobile app developed during a 24h Hackathon at CGI which might be open sourced at some point</li>
<li>Another one called &lsquo;Dev Cube&rsquo; created at an university, where you get to decorate you virtual cubicle</li>
</ul>


<p><a href="https://www.youtube.com/watch?v=hfT2_HxOQdk"><img class="center" src="/imgs/2016-10-14-3-more-great-talks-from-javaone-2016/quincy-adams.jpg" title="The speaker demoing his code quality game" ></a></p>

<p>At the end of the talk, he gave the following recommendations :</p>

<ul>
<li>Understand the needs of all to respond to everyone&rsquo;s personal goals</li>
<li>Don&rsquo;t assign things to do, that&rsquo;s not fun, give rewards instead</li>
<li>Keep managers out of the picture</li>
<li>To keep it going, you need regular improvements, special events and new rules</li>
<li>KISS !</li>
</ul>


<p>Playing at work might not be unproductive in the end !</p>

<p>The same <a href="https://www.youtube.com/watch?v=hfT2_HxOQdk">talk given at NLJug</a>, unfortunately, it&rsquo;s in Dutch. English slides are <a href="https://static.rainfocus.com/oracle/oow16/sess/14625567983370011wPS/ppt/increasing%20code%20quality%20with%20gamification.pdf">here</a> though.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Most Common Ways To Speed up an algorithm]]></title>
    <link href="http://philippe.bourgau.net/most-common-ways-to-speed-up-an-algorithm/"/>
    <updated>2016-01-20T05:14:00+01:00</updated>
    <id>http://philippe.bourgau.net/most-common-ways-to-speed-up-an-algorithm</id>
    <content type="html"><![CDATA[<p>Algorithms are <em>hard</em>, and making them fast is even harder &hellip; But there are shortcuts that work quite often !</p>

<p><img class="center" src="/imgs/2016-01-20-most-common-ways-to-speed-up-an-algorithm/shortcut-road.jpg" title="A street panel called Short Cut Road" ></p>

<h2>The Challenge</h2>

<p>Imagine you just arrived to your new job, and you are asked to make a part of the system faster. After a bit of investigation, you discover that most of the time is spent in some weird in-house algorithm that seems to take forever. How can you optimize this without deep knowledge neither in algorithm science nor in the code itself ?</p>

<p>Here are 4 tricks to reduce the complexity of algorithms (I&rsquo;m using fairly basic examples for the sake of understandably. Most of these exact examples could be done better using standard libraries, but I hope it will be easy to adapt to other situations) :</p>

<h3>Replace a nested loop by first building a hash and then looping</h3>

<p>```ruby</p>

<h1>before</h1>

<p>orders.each do |order|
  client = list_of_clients.find {|client| client.id = order.client_id }
  handle_order(order, client)
end</p>

<h1>after</h1>

<p>clients_by_id = {}
list_of_clients.each do |client|
  clients_by_id[client.id] = client
end
orders.each do |order|
  handle_order(order, clients_by_id[order.client_id])
end
```
This reduces the complexity from O(2) to O(1). This is tremendous. On large lists O(2) algorithms are terrible.</p>

<h3>Remove unnecessary accumulations</h3>

<p>The most classic example is the use of a string buffer :</p>

<p>```ruby
// Before
report = &ldquo;&rdquo;
line_items.each do |line_item|
  report += line_item.to_s + &ldquo;\n&rdquo;
end</p>

<p>// After
report = []
line_items.each do |line_item|
  report &lt;&lt; line_item.to_s
  report &lt;&lt; &ldquo;\n&rdquo;
end
report.join
```
Again, this reduces the complexity from O(2) to O(1). Every language has variants of Java&rsquo;s StringBuilders. This does not only apply for strings, it works any time you are repeatedly accumulating results inside a loop but where you could do it only once at the end.</p>

<h3>Cache intermediate or previous results</h3>

<p>This is called <a href="https://en.wikipedia.org/wiki/Memoization">memoization</a>. Some algorithms (especially recursive algorithms) repeatedly compute the same thing again and again. Spotting this pattern is an opportunity to move an algorithm out of exponential complexity. For example, <a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm">Dijsktra&rsquo;s algorithm</a> for finding the shortest path in a graph uses this technique to go from O(e<sup>n</sup>) to O(n<sup>2</sup>) complexity. If you suspect this could be helpful, your best friend is logging to trace actual parameters and results.</p>

<p><a href="https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#/media/File:Dijkstras_progress_animation.gif"><img class="center" src="/imgs/2016-01-20-most-common-ways-to-speed-up-an-algorithm/Dijkstras_progress_animation.gif" title="Dijsktra&rsquo;s path finding algorithm animated (from Wikipedia)" ></a></p>

<p>A word of caution : using memoization with mutable inputs or outputs will harm your mental health.</p>

<h3><a href="https://en.wikipedia.org/wiki/Merge_algorithm#Merging_two_lists">Zip merge</a></h3>

<p>There are 2 ways to merge sorted lists into a unique sorted list : the fast, and the slow &hellip;</p>

<p>```ruby</p>

<h1>The slow</h1>

<p>(list_1 + list_2).sort</p>

<h1>The fast</h1>

<p>i_1 = 0
i_2 = 0
result = []</p>

<p>while i_1 &lt; list_1.size and i_2 &lt; list_2.size
  if list_1[i_1] &lt;= list_2[i_2]</p>

<pre><code>result &lt;&lt; list_1[i_1]
i_1 += 1
</code></pre>

<p>  elsif list_2[i_2] &lt;= list_1[i_1]</p>

<pre><code>result &lt;&lt; list_2[i_2]
i_2 += 1
</code></pre>

<p>  end
end</p>

<p>while i_1 &lt; list_1.size
  result &lt;&lt; list_1[i_1]
  i_1 += 1
end</p>

<p>while i_2 &lt; list_2.size
  result &lt;&lt; list_2[i_2]
  i_2 += 1
end
```</p>

<p>Obviously, the slow version is a lot easier to read than the fast one. And the fast one could benefit from a bit of refactoring also &hellip; Nevertheless, the slow version is at best in O(n.ln(n)) whereas the fast on is in O(n). On large data, that can make a big difference.</p>

<h2>Is that all ?</h2>

<p>Obviously not, there can be a lot of other things going on slowly in algorithms, but from my experience, a software engineer can have a good career without knowing more about algorithms theory than that.</p>

<p>In the end, you manage to optimize this in-house algorithm, you become the company&rsquo;s hero, you need your job and get a pay raise !</p>

<h2>End word</h2>

<p>The fact is, in 15 years of writing software, I did not write a lot of algorithmic code. I can categories my working with algorithms in 3 :</p>

<ol>
<li>Write a simple algorithm for a non performance critical feature</li>
<li>Optimize an existing somewhat algorithmic part of code</li>
<li>Write a complex algorithm for a performance critical part of the system</li>
</ol>


<p>Case 1. is not really an issue since however the code will be written, it will run fast enough. If you&rsquo;re in case 3, there&rsquo;s no shortcut, you&rsquo;ll have to dig deep into algorithms and optimization, this happens rather rarely though. This leaves us with case 2, which I just wrote about.</p>

<p>Interestingly, <a href="http://www.murex.com">my current job</a> is deep into case 3 ! We&rsquo;re building a risk engine for corporate markets and are borrowing a lot of techniques from database science &hellip; which is, you can guess, rather algorithmic !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How To Write Good Performance Stories]]></title>
    <link href="http://philippe.bourgau.net/how-to-write-good-performance-stories/"/>
    <updated>2016-01-08T07:58:00+01:00</updated>
    <id>http://philippe.bourgau.net/how-to-write-good-performance-stories</id>
    <content type="html"><![CDATA[<p>If you&rsquo;re having difficulties writing good performance related stories for your project, that&rsquo;s no surprise ! We&rsquo;ve been through the same troubles and we found a way that works a lot better.</p>

<p><img class="center" src="/imgs/2016-01-08-how-to-write-good-performance-stories/speed.jpg" title="A Mb speed counter" ></p>

<h2>Solution 1 : <a href="/performance-is-a-feature/">Performance is a feature</a></h2>

<p>Right ? In typical agile way, a story about performance would be written like</p>

<blockquote><p>As marketing, I want the page load to perform under 1 second, In order for the customers to stay on the site</p></blockquote>

<p>If the performance bottleneck and the fix are obvious, that might work very well. If that&rsquo;s your case, then go on, that&rsquo;s the simplest way!</p>

<p>Unfortunately for us, we are not in that case. <a href="http://www.murex.com">At work</a> we are building a risk engine and we need to perform extremely well on a wide set of different scenarios. Imagine a story such as</p>

<blockquote><p>As a risk manager, I want the VAR scenario to compute in less than 1 second, in order to have real time data</p></blockquote>

<ul>
<li>we&rsquo;re pretty sure that there won&rsquo;t be 1 but many bottlenecks to fix before reaching the expected performance</li>
<li>speeding up the VAR scenario might slow down other scenarios</li>
</ul>


<p>That makes this kind of story too fuzzy. We tried them, and we had difficulties to estimate and close them.</p>

<h2>Solution 2 : Back to the traditional way</h2>

<p>Without an agile backlog, developers would have worked on tasks such as</p>

<blockquote><p>Add caching to the computation engine</p></blockquote>

<p>That&rsquo;s estimable, but we&rsquo;ve got no clue of the <em>why</em> ! When it&rsquo;s done, we won&rsquo;t be able to know whether it&rsquo;s worth to keep it or not. In fact, it&rsquo;s just not a <a href="https://en.wikipedia.org/wiki/INVEST_(mnemonic">story</a>) !</p>

<h2>Solution 3 : Mixing both</h2>

<p>Here is how we we are now writing performance stories at work :</p>

<blockquote><p>As a risk manager, I want to have caching in the computation engine, in order to the VAR scenario compute under 1 second (in order to have real time data)</p></blockquote>

<p>It&rsquo;s now estimable, we know what it&rsquo;s there for. It&rsquo;s obviously not enough though : we know that we will very likely need to do other performance stories after this one.</p>

<h2>Embrace uncertainty</h2>

<p><img class="center" src="/imgs/2016-01-08-how-to-write-good-performance-stories/engine.jpg" title="A Maserati engine" ></p>

<p>The fact is that in our context, getting better performances is <em>hard</em> :</p>

<ul>
<li>it requires a lot of work</li>
<li>we don&rsquo;t know how much at the beginning</li>
<li>we often try things that don&rsquo;t work</li>
</ul>


<p>This makes the whole project more uncertain, so we&rsquo;re better off embracing this uncertainty in the way we write and prioritize our performance stories.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[What Optimization Should We Work On (Lean Software Development Part 5)]]></title>
    <link href="http://philippe.bourgau.net/what-optimization-should-we-work-on-lean-software-development-part-5/"/>
    <updated>2015-03-26T20:30:00+01:00</updated>
    <id>http://philippe.bourgau.net/what-optimization-should-we-work-on-lean-software-development-part-5</id>
    <content type="html"><![CDATA[<p>At work, we are building a risk aggregation system. As it&rsquo;s dealing with a large bunch of numbers, it&rsquo;s a huge heap of optimizations. Once that its most standard features set is supported, our job mostly consists of making it faster.</p>

<p>That&rsquo;s were we are now doing.</p>

<p><img class="center" src="/imgs/2015-03-26-what-optimization-should-we-work-on-lean-software-development-part-5/turtle.jpg" title="A turtle with a rocket on the back" ></p>

<h1>How do we choose which optimization to work on ?</h1>

<p>The system still being young, we have a wide range of options to optimize it. To name just a few : caches, better algorithms, better low level hardware usage &hellip;</p>

<p>It turns out that we can use the speedup factor as a substitute for business value and use known techniques to help us to make the best decisions.</p>

<h2>Let&rsquo;s walk through an example</h2>

<h3>I. List the optimizations you are thinking of</h3>

<p>Let&rsquo;s suppose we are thinking of the following 3 optimizations for our engine</p>

<ul>
<li>Create better data structures to speed up the reconciliation algorithm</li>
<li>Optimize the reconciliation algorithm itself to reduce CPU cache misses</li>
<li>Minimize boxing and unboxing</li>
</ul>


<h3>II. Poker estimate the story points and speedup</h3>

<p>Armed with these stories, we can poker estimate them, by story points and by expected speedup.
As a substitute for WSJF, we will then be able to compute the speedup rate per story point.
We will then just have to work on the stories with the highest speedup rate first.</p>

<table>
<thead>
<tr>
<th>Title                   </th>
<th> Story Points  </th>
<th> /10    </th>
<th> /2     </th>
<th> -10%    </th>
<th> ~  </th>
<th> +10%   </th>
<th> x2      </th>
<th> x10     </th>
<th> Expected Speedup ratio* </th>
<th> Speedup rate / story point**</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Structures     </td>
<td> 13        </td>
<td>        </td>
<td>        </td>
<td>             </td>
<td>        </td>
<td> 4 votes</td>
<td> 5 votes </td>
<td>         </td>
<td> x 1.533                 </td>
<td> x 1.033</td>
</tr>
<tr>
<td>Algorithm           </td>
<td> 13        </td>
<td>    </td>
<td> 1 vote </td>
<td> 1 vote      </td>
<td> 2 votes</td>
<td> 1 vote </td>
<td> 2 votes </td>
<td> 2 votes </td>
<td> x 1.799                 </td>
<td> x 1.046</td>
</tr>
<tr>
<td>Boxing                  </td>
<td> 8     </td>
<td>    </td>
<td>        </td>
<td>             </td>
<td>        </td>
<td> 9 votes</td>
<td>         </td>
<td>         </td>
<td> x 1.1                   </td>
<td> x 1.012</td>
</tr>
</tbody>
</table>


<p><sup><em>* Expected speedup ratio is the logarithmic average of the voted speedups</em></sup><br>
<sup><em>** Speedup rate is &ldquo;speedup<sup>(1/ story points)</sup>&rdquo;</em></sup></p>

<p>So based on speedup rate, here is the order in which we should perform the stories :</p>

<ol>
<li>Algorithm</li>
<li>Data Structures</li>
<li>Boxing</li>
</ol>


<h3>III. And what about the risks ?</h3>

<p><img class="center" src="/imgs/2015-03-26-what-optimization-should-we-work-on-lean-software-development-part-5/danger.jpg" title="A danger zone panel" ></p>

<p>This poker estimation tells us something else &hellip;</p>

<blockquote><p>We don&rsquo;t have a clue about the speedup we will get by trying to optimize the algorithm !</p></blockquote>

<p>The votes range from /2 to x10 ! This is the perfect situation for an XP spike.</p>

<table>
<thead>
<tr>
<th>Title </th>
<th> Story points </th>
<th> Expected Speedup rate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Algorithm spike : measure out of context CPU cache optimization speedup </td>
<td> 2 </td>
<td>   ?</td>
</tr>
</tbody>
</table>


<br>


<p>In order to compute the expected speedup rate, let&rsquo;s suppose that they are 2 futures, one where we get a high speedup and another where we get a low one.</p>

<p>They are computed by splitting the votes in 2 :</p>

<ul>
<li><em>low_speedup = 0.846</em></li>
<li><em>high_speedup = 3.827</em></li>
</ul>


<h4>If the spike succeeds</h4>

<p>We&rsquo;ll first work on the spike, and then on the algorithm story. In the end, we would get the speedup of the algorithm optimization.</p>

<ul>
<li><em>spike_high_speedup = high_speedup = 3.827</em></li>
</ul>


<h4>If the spike fails</h4>

<p>We&rsquo;ll also start by working on the spike. Afterwards, instead of the algorithm story, we&rsquo;ll tackle another optimization stories, yielding our average speedup rate for the duration of the algorithm story. The average speedup rate can be obtained from historical benchmark data, or by averaging the speedup rate of the other stories.</p>

<ul>
<li><em>average_speedup_rate = (1.033 * 1.011)<sup>&frac12;</sup> = 1.022</em></li>
<li><em>spike_low_speedup = average_speedup_rate<sup>story_points</sup> = 1.02213 = 1.326</em></li>
</ul>


<h4>Spike speedup rate</h4>

<p>We can now compute the average expected speedup rate for the full period &lsquo;spike &amp; algorithm&rsquo; stories. From this we will be able to get the speedup rate and finally, to prioritize this spike against the other stories in our backlog.</p>

<ul>
<li><em>spike_speedup = (spike_low_speedup * spike_high_speedup)<sup>&frac12;</sup> = 2.253</em></li>
<li><em>spike_speedup_rate = spike_speedup<sup>1/(spike_story_points + algorithm_story_points)</sup> = 2.253<sup>1/(2 + 13)</sup> = 1.056</em></li>
</ul>


<h3>IV. Putting it all together</h3>

<p>Here are all the speedup rate for the different stories.</p>

<table>
<thead>
<tr>
<th>Title </th>
<th> Speedup rate / story point</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Structure  </td>
<td> x 1.033</td>
</tr>
<tr>
<td>Algorithm           </td>
<td> x 1.046</td>
</tr>
<tr>
<td>Boxing                  </td>
<td> x 1.012</td>
</tr>
<tr>
<td>Algorithm spike         </td>
<td> x 1.056</td>
</tr>
</tbody>
</table>


<br>


<p>Finally, here is the optimal order through which we should perform the stories :</p>

<ul>
<li>Algorithm spike</li>
<li>Algorithm (only if the spike proved it would work)</li>
<li>Data Structures</li>
<li>Boxing</li>
</ul>


<h2>Summary</h2>

<p>The math are not that complex, and a simple formula can be written to compute the spike speedup rate :</p>

<p><img class="center" src="/imgs/2015-03-26-what-optimization-should-we-work-on-lean-software-development-part-5/poc_speedup_rate.png" title="Formula for a spike speedup rate" ></p>

<p>I think most experienced engineers would have come to the same conclusion by gut feeling &hellip;</p>

<p>Nevertheless I believe that systematically applying the such method when prioritizing optimizations can lead to a greater speedup rate than the competition in the long run. This is a perfect example where taking measured risks can payoff !</p>

<p>This was part 5 of my <a href="/the-flow-book-summary-lean-software-development_part_1/">Lean Software Development Series</a>. Part 4 was <a href="/measure-the-business-value-of-your-spikes-and-take-high-payoff-risks-lean-software-development-part-4/">Measure the business value of your spikes and take high payoff risks</a>, Part 5 will be <a href="/you-dont-have-to-ask-your-boss-for-a-fast-build-lean-software-development-part-6/">You don&rsquo;t have to ask your boss for a fast build</a>.</p>
]]></content>
  </entry>
  
</feed>
