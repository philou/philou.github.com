<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: testing | Philippe Bourgau's blog]]></title>
  <link href="http://philippe.bourgau.net/blog/categories/testing/atom.xml" rel="self"/>
  <link href="http://philippe.bourgau.net/"/>
  <updated>2016-08-24T04:39:57+00:00</updated>
  <id>http://philippe.bourgau.net/</id>
  <author>
    <name><![CDATA[Philippe Bourgau]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[RSpecProxies now supports .to receive(xxx)... syntax]]></title>
    <link href="http://philippe.bourgau.net/rspecproxies-now-supports-to-receive-xxx-dot-dot-dot-syntax/"/>
    <updated>2016-08-23T04:47:00+00:00</updated>
    <id>http://philippe.bourgau.net/rspecproxies-now-supports-to-receive-xxx-dot-dot-dot-syntax</id>
    <content type="html"><![CDATA[<p><img class="center" src="/imgs/2016-08-23-rspecproxies-now-supports-to-receive-xxx-dot-dot-dot-syntax/test_probes.jpg" title="Hardware test probes" ></p>

<p>Pure mocks are dangerous. They let defect go through, give a false sense of security and are difficult to maintain.</p>

<p>I&rsquo;ve already talked about it <a href="/hitting-the-middle-ground-between-classicist-and-mockist-tdd/">before</a> but since then, <a href="http://david.heinemeierhansson.com/2014/tdd-is-dead-long-live-testing.html">DHH announced that he was quitting TDD</a>, the <a href="http://martinfowler.com/articles/is-tdd-dead/">Is TDD Dead ?</a> debate took place, and the conclusion is that <a href="https://www.thoughtworks.com/insights/blog/mockists-are-dead-long-live-classicists">mockist are dead</a>.</p>

<p>They are still times when mocks feel much simpler than any other things. For example, imagine your process leaks and crashes after 10 hours, the fix is to pass an option to a thirdparty, how would you test this in a fast test ? That&rsquo;s exactly the kind of situation where using test proxies saves you from mocks. A test proxy defers everything to the real object but also features unintrusive hooks and probes that you can use in your test. If you want a code example, check <a href="https://github.com/philou/mes-courses/commit/2c9fce17f9b59d0b3828f309015c07b17cceddf4?diff=split">this commit</a>, where I refactored a rails controller test from mocks to a RSpecProxies (v0.1).</p>

<p>I created RSpecProxies <a href="/my-new-gem-for-creating-rspec-proxies/">a while ago</a>, a while ago, and it&rsquo;s syntax made it alien to the RSpec work, it needed an update. <a href="http://rspec.info">RSpec</a> now supports basic proxying with partial stubs, spies, the <code>and_call_original</code> and the <code>and_wrap_original</code> methods. <a href="https://github.com/philou/rspecproxies">RSpecProxies 1.0</a> is a collection of hooks built on top of these to make proxying easier, with a syntax that will be familiar to RSpec users.</p>

<h2>Before original hook</h2>

<p>This hook is triggered before a call a method. Suppose you want to simulate a bad connection :</p>

<p>```ruby
it &lsquo;can simulate unreliable connection&rsquo; do
  i = 0
  allow(Resource).to receive(:get).and_before_calling_original { |*args|</p>

<pre><code>i += 1
raise RuntimeError.new if i % 3 == 0
</code></pre>

<p>  }</p>

<p>  resources = Resource.get_at_least(10)</p>

<p>  expect(resources.size).to eq(10)
end
```</p>

<h2>After original hooks</h2>

<p>RSpecProxies provides the same kind of hook after the call :</p>

<p>``` ruby
it &lsquo;can check that the correct data is used (using and_after_calling_original&rsquo; do
  user = nil
  allow(User).to receive(:load).and_after_calling_original { |result| user = result }</p>

<p>  controller.login(&lsquo;joe&rsquo;, &lsquo;secret&rsquo;)</p>

<p>  expect(response).to include(user.created_at.to_s)
end
```</p>

<p>Here we are capturing the return value to use it later in the test. For this special purpose, RSpecProxies also provides 2 other helpers :</p>

<p>``` ruby</p>

<h1>Store the latest result in @user of self</h1>

<p>allow(User).to receive(:load).and_capture_result_into(self, :user)</p>

<h1>Collect all results in the users array</h1>

<p>users = []
allow(User).to receive(:load).and_collect_results_into(users)
```</p>

<h2>Proxy chains</h2>

<p>RSpec mocks provides the <code>message_chain</code> feature to do build chains of stubs. RSpecProxy provides a very similar proxy chain concept. The main difference is that it creates proxies along the way, and not pure stubs. Pure stubs assume that you are mocking everything, but as our goal is to mock as little as possible, using proxies makes more sense.</p>

<p>When using a mockist approach, the message chain is a bad smell because it makes your tests very brittle by depending on a lot of implementation. In contrast, proxy chains are meant to be used where they are the simplest way to inject what you need, without creating havoc.</p>

<p>For example, suppose you want to display the progress of a very slow background task. You could mock a lot of your objects to have a fast test, of if you wanted to avoid all the bad side effects of mocking, you could run the background task in your test, and have a slow test &hellip; Or, you could use a chain of proxies :</p>

<p>``` ruby
it &lsquo;can override a deep getter&rsquo; do
  allow(RenderingTask).to proxy_message_chain(&ldquo;load.completion_ratio&rdquo;) { |e| e.and_return(0.2523) }</p>

<p>  controller.show</p>

<p>  expect(response).to include(&lsquo;25%&rsquo;)
end
```</p>

<p>Here the simplest thing to do is just to override a small getter, because from a functionnal point of view, that&rsquo;s exactly what we want to test.</p>

<h2>Last word</h2>

<p>The code is on <a href="https://github.com/philou/rspecproxies">github</a>, v1.0.0 is on <a href="https://rubygems.org/gems/rspecproxies/versions/0.1.0">rubygems</a>, it requires Ruby v2.2.5 and RSpec v3.5, the license is MIT, help in any form are welcome !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How We Started Exploratory Testing]]></title>
    <link href="http://philippe.bourgau.net/how-we-started-exploratory-testing/"/>
    <updated>2016-01-08T18:18:00+00:00</updated>
    <id>http://philippe.bourgau.net/how-we-started-exploratory-testing</id>
    <content type="html"><![CDATA[<p>Manual testing is important. Here is how we got to love exploratory testing.</p>

<p><img class="center" src="/imgs/2016-01-08-how-we-started-exploratory-testing/explore.jpg" title="A map and a telescope for exploration" ></p>

<h2>Initial situation</h2>

<p><a href="http://www.murex.com">At work</a> we are building a risk computation engine for the financial markets. It uses a DSL to describe the exact computations to estimate the risk on the data it knows. This in itself is already complex enough to justify the heavy investment in automated testing we did.</p>

<p>With 90% of automated test coverage, Cucumber scenarios to verify quality, everything should just work &hellip; shouldn&rsquo;t it ?</p>

<h2>First try at exploratory testing</h2>

<p><a href="http://www.amazon.com/Art-Agile-Development-James-Shore/dp/0596527675/ref=sr_1_1?ie=UTF8&amp;qid=1452279644&amp;sr=8-1&amp;keywords=the+art+of+agile+development"><img class="center" src="/imgs/2016-01-08-how-we-started-exploratory-testing/art-of-agile-development.jpg" title="The cover of the Art Of Agile Development" ></a></p>

<p>In <a href="http://www.amazon.com/Art-Agile-Development-James-Shore/dp/0596527675/ref=sr_1_1?ie=UTF8&amp;qid=1452279644&amp;sr=8-1&amp;keywords=the+art+of+agile+development">The art of agile development</a>, James Shore details the practice of exploratory testing as a great way of both :</p>

<ul>
<li>improving the quality of the product by finding bugs</li>
<li>improving the process</li>
</ul>


<p>That&rsquo;s why we gave it a try. Here is the recipe for an exploratory session :</p>

<ol>
<li>Book 1 hour for the full team to do exploratory testing</li>
<li>Prepare a downloadable zip with all the material required to run and test your software</li>
<li>Ask everyone to pick a particular aspect of the system to test during this session</li>
<li>Record bugs when you find one</li>
<li>Spend 30 minutes just after the session to filter duplicate bugs and make sure they are well described</li>
</ol>


<p>Obviously, we also added our special sauce</p>

<ol>
<li>We were to do exploratory testing in pairs, as we do programming, to find more bugs</li>
<li>We gamified it by granting a price to the pair that finds the most bugs. Do you remember how I brought <a href="/how-to-setup-a-weekly-fruit-basket-in-no-time/">fruits for sale in the office</a> ? It turns out we are slowly earning money with the fruits &hellip; enough for the price to be 5 fruits each for the wining pair !</li>
</ol>


<p>This transformed developers into ferocious testers ! I guarantee that with such incentives you&rsquo;ll find bugs &hellip; as we did.</p>

<p><a href="/how-to-setup-a-weekly-fruit-basket-in-no-time/"><img class="center" src="/imgs/2016-01-08-how-we-started-exploratory-testing/fruits-basket.jpg" title="Our weekly fruit basket at work" ></a></p>

<h2>Doing it systematically</h2>

<p>We took some time to fix all these bugs during a few sprints. And did another exploratory testing session a few months after &hellip;</p>

<p>As we were still finding bugs in the second session, we decided to make them part of the every sprint. As we got better at testing, a lot of bugs started to get uncovered ! So much that we had to change something.</p>

<h2>Improving our process</h2>

<p>We meet in retrospective and here is what we decided :</p>

<ol>
<li>Fix all bugs before working on any other story (obviously, automated tests are added in the process)</li>
<li>Classify what exactly is a bug. For example, for us, a bug is something that used to work or silently returns bad results or corrupts the data</li>
<li>Add exploratory testing by another pair to our definition of done</li>
</ol>


<p>The number of bugs we find during exploratory testing sessions is starting to decrease. We hope that we&rsquo;ll soon be able to do exploratory testing on the fly, as part of our daily work and to completely remove the specific sessions.</p>

<h2>Benefits</h2>

<p>Exploratory testing brought us a lot.</p>

<ul>
<li>Obviously, the product is a lot more solid</li>
<li>We are surely saving time that would have been lost if the bugs had been uncovered by the users</li>
<li>Fixing the bugs forced us to fix some technical debt : bugs often came from areas of the code that we were not so proud or confident of</li>
</ul>


<p>Exploratory testing is a nobrainer. All teams should do it.</p>

<p>So, in the end, as in the old days, we are back to regular manual testing &hellip; but only for exploration.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Agile Change Management Viral Hack]]></title>
    <link href="http://philippe.bourgau.net/the-agile-change-management-viral-hack/"/>
    <updated>2015-05-23T05:51:00+00:00</updated>
    <id>http://philippe.bourgau.net/the-agile-change-management-viral-hack</id>
    <content type="html"><![CDATA[<p>We just discovered a hack to spread agile (<a href="http://en.wikipedia.org/wiki/Behavior-driven_development">BDD</a> by the way) through an organization. It works provided :</p>

<ul>
<li>There is a BDD testing expert in your team</li>
<li>Your team is using the work of another software team from your company</li>
</ul>


<p>If this team does not use agile practices, they are likely to regularly create regressions or to be late at providing new versions.</p>

<p>Use your client role in the relation, and propose your help ! Spend some time with them to help them put automated customer tests in place. Be genuinely nice with them, show example, be available and, obviously, bring improvement. With some chance, they might soon be asking for more.</p>

<p><code>ruby
Given there are too many bugs
When you can help
Then DO IT !
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Performance is a feature]]></title>
    <link href="http://philippe.bourgau.net/performance-is-a-feature/"/>
    <updated>2015-01-19T06:46:00+00:00</updated>
    <id>http://philippe.bourgau.net/performance-is-a-feature</id>
    <content type="html"><![CDATA[<p>Now that is a widespread title for blog articles ! Just <a href="https://www.google.fr/search?sourceid=chrome-psyapi2&amp;ion=1&amp;espv=2&amp;ie=UTF-8&amp;q=performance%20is%20a%20feature">search Google</a>, and you&rsquo;ll find &ldquo;Performance is a feature&rdquo; in <a href="http://blog.codinghorror.com/performance-is-a-feature/">Coding Horror</a> and <a href="http://coffeeonthekeyboard.com/performance-is-a-feature-623/">others</a>.</p>

<p><a href="http://www.motorstown.com/50701-dragster-jet.html"><img class="center" src="/imgs/2015-01-19-performance-is-a-feature/dragster.jpg" title="A Dragster at full speed" ></a></p>

<h1>What&rsquo;s in it for us ?</h1>

<p>If performance is indead a feature, then it can be managed like any feature :</p>

<ul>
<li><p>It should result from use cases</p>

<blockquote><p>During use case X, the user should not wait more than Y seconds for Z</p></blockquote></li>
<li><p>It can be split into user stories</p></li>
</ul>


<blockquote><ul>
<li>Story 1: During use case X, the user should not wait more than 2*Y seconds for Z</li>
<li>Story 2: During use case X, the user should not wait more than Y seconds for Z</li>
</ul>
</blockquote>

<ul>
<li>They can be prioritized against other stories</li>
</ul>


<blockquote><ul>
<li>Let&rsquo;s forget about performance for now and deliver functionality A as soon as ready, we&rsquo;ll speed things up later.</li>
<li>Let&rsquo;s fix basic performance constraints for use case X for now, every story will have to comply with these constraints later.</li>
</ul>
</blockquote>

<ul>
<li>The performance on these use cases should be automatically tested and non regressed</li>
</ul>


<blockquote><ul>
<li>If we slow things too much and these tests breaks, we&rsquo;ll have to optimize the code.</li>
<li>But as long as we don&rsquo;t break the tests, it&rsquo;s ok to unoptimize the code !</li>
</ul>
</blockquote>

<p>Maybe that&rsquo;s a chance to stop performance related gut feeling quarrels !</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Enabling agile practices and elephant taming]]></title>
    <link href="http://philippe.bourgau.net/enabling-agile-practices-and-elephant-taming/"/>
    <updated>2014-06-15T21:37:00+00:00</updated>
    <id>http://philippe.bourgau.net/enabling-agile-practices-and-elephant-taming</id>
    <content type="html"><![CDATA[<p>Everybody knows about the agile software development promise &ldquo;Regularly and continuously deliver value&rdquo;. This is how it is supposed to work :</p>

<ul>
<li>Iterative</li>
<li>Focusing on what is needed now</li>
<li>Release as soon as possible</li>
<li>Planning small stories according to the team&rsquo;s velocity</li>
</ul>


<p><img class="center" src="/imgs/2014-06-15-enabling-agile-practices-and-elephant-taming/squirrel.jpg" title="A business A squirrel jumping from one tree to another (source mayamumu.centerblog.net)" ></p>

<p>It all seems common sense and simple. Especialy for people who don&rsquo;t code. That&rsquo;s not the whole story though, let&rsquo;s have a look at a few variations :</p>

<p>Suppose a team uses <a href="http://www.scrum.org">Scrum</a> but does not do any automated testing. As soon as the software will be used, bugs will create havoc in the planning. The velocity will quickly fall, within a few monthes, the team won&rsquo;t be able to add any value. Surely, things could be improved with some rewrite and upfront design &hellip; this does not sound like Scrum anymore.</p>

<p>Now let&rsquo;s suppose that another team is also using Scrum, uses automated tests, but <a href="/sprints-are-not-sprints/">missunderstood Sprint</a> and KISS for quick-and-dirty-coding. Hopefully, this team won&rsquo;t get too many bugs in production ! Unfortunately, any change to the source code will trigger hundreds of test failures : again, the velocity will decrease. I&rsquo;ve been in such projects, in about 2 years, the team got really slow, and might eventually drop their test suit &hellip;</p>

<p>These two examples show that automated testing improves the situation, but also that it is not enough ! There are quite a few agile practices that are in fact <em>enabling</em> practices. These are the practices that are required for the process to accomplish the agile promise described at the begining of this article. Most come from <a href="http://www.extremeprogramming.org/">eXtreme Programming</a> and have been reincarnated through <a href="http://manifesto.softwarecraftsmanship.org/">Software Craftsmanship</a>. That&rsquo;s what Kent Beck meant when he said that XP practices reinforce each other. Here are a few examples :</p>

<p>For example let&rsquo;s take <strong>coding standards</strong> and <strong>pair programming</strong> which really seem to be a programmer choice.
It turns out that they help to achieve <strong>collective code ownership</strong>.
Which in turn helps to get &lsquo;switchable&rsquo; team members.
Which helps to make good team estimates.
Which is required to have have a reliable <strong>velocity</strong>.
Which is a must have to regularly <strong>deliver value</strong> on commitment !</p>

<p>It turns out that all of the other original <a href="http://www.extremeprogramming.org/rules.html">XP practices</a> help to achieve the agile promise.</p>

<p><img class="center" src="/imgs/2014-06-15-enabling-agile-practices-and-elephant-taming/elephant-in-the-room.jpg" title="A business meeting with a real elephant in the room" ></p>

<p>After a lot of time spent writing software, I now tend to think of the code as the elephant in the room. It directly or indirectly constrains every decision that is make. Recognize and tame your elephant or you&rsquo;ll get carted away &hellip;</p>

<p>&hellip; or dragged away &hellip;</p>

<p>&hellip; or trampled &hellip;</p>
]]></content>
  </entry>
  
</feed>
