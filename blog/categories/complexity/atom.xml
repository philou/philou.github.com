<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: complexity | Philippe Bourgau's blog]]></title>
  <link href="http://philippe.bourgau.net/blog/categories/complexity/atom.xml" rel="self"/>
  <link href="http://philippe.bourgau.net/"/>
  <updated>2015-11-19T21:52:59+00:00</updated>
  <id>http://philippe.bourgau.net/</id>
  <author>
    <name><![CDATA[Philippe Bourgau]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Programming as an exponential problem]]></title>
    <link href="http://philippe.bourgau.net/programming-as-an-exponential-problem/"/>
    <updated>2014-02-21T06:30:00+00:00</updated>
    <id>http://philippe.bourgau.net/programming-as-an-exponential-problem</id>
    <content type="html"><![CDATA[<p>As said Tom Cargill</p>

<blockquote><p>The first 90% of the code accounts for the first 90% of the development time. The remaining 10% of the code accounts for the other 90% of the development time.</p></blockquote>

<p>By extrapolation, this would mean that every time we increase the requirements by 10%, we need to double the total development time ! That would mean that solution complexity is an exponential function of the complexity of the problem.</p>

<p>That could explain why techniques that work well for small problems don&rsquo;t work well at all for large problems, and vice et versa. For example</p>

<table>
<thead>
<tr>
<th align="center"> In the small (think one page script) </th>
<th align="center"> In the large (think multi millions lines system)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"> Dynamic typing                       </td>
<td align="center"> Static typing</td>
</tr>
<tr>
<td align="center"> Mutable globals                      </td>
<td align="center"> Immutability</td>
</tr>
<tr>
<td align="center"> Imperative style                     </td>
<td align="center"> Declarative style</td>
</tr>
<tr>
<td align="center"> Manual memory management             </td>
<td align="center"> Garbage collection</td>
</tr>
<tr>
<td align="center"> Shared memory                        </td>
<td align="center"> Message passing</td>
</tr>
</tbody>
</table>


<br/>


<p>Just for fun, let&rsquo;s suppose that we could deduce a unique constant C for every language such that</p>

<p><img class="center" src="/imgs/2014-02-21-programming-as-an-exponential-problem/formula.png" title="Secret formula linking problem and solution complexities" ></p>

<p>Here is a plot of this formula with different values of C (0.5, 1 and 2)</p>

<p><img class="center" src="/imgs/2014-02-21-programming-as-an-exponential-problem/close-plot.png" title="Plot of the formula for different C constant values" ></p>

<p>We can see that small values of C are best for small problems, whereas greater values are evolve better with larger problems. For a given problem, there is quite a difference in the solution complexity, if the formula was true, and that we knew in which zone of complexity our problem will always be, we could choose the appropriate technology ! Experienced engineers already have the gut knowledge about how to chose the right tool for the job !</p>

<p>That&rsquo;s not all, let&rsquo;s have a bird&rsquo;s eye view of the same formulas</p>

<p><img class="center" src="/imgs/2014-02-21-programming-as-an-exponential-problem/wide-plot.png" title="Same plot at a larger scale" ></p>

<p>I increased the maximum problem complexity by a factor of 3, I had to multiply the solution complexity by 100 ! In the end, these exponential curves all seem frighteningly vertical. This could explain why the divide and conquer approach works so well in software : 2e<sup>x</sup> &lt; e<sup>2x</sup>. Abstract and powerful APIs might be our best weapon against complexity.</p>

<p>People behaviour does not match this exponential hypothesis though :</p>

<ul>
<li>At work, I&rsquo;ve seen quite a few projects started from scratch, and everybody expecting it to maintain it&rsquo;s initial speed during its whole lifetime</li>
<li>Some recent hiring or investing trend seem to rely on hackathons, startup week ends, or coding games, all &lsquo;in the small&rsquo; exercises</li>
<li>I&rsquo;ve observed in quick and dirty overtime work to meet a deadline &hellip; If productivity is proportional to the solution complexity, that crunch mode would be completely unproductive</li>
</ul>


<p>This leads to more interesting questions :</p>

<ul>
<li>Is my exponential model complete garbage ?</li>
<li>Or are humans particularly bad at forecasting an exponential behaviour ?</li>
<li>If so, what practices could we adopt to stop relying on this misleading gut feeling ?</li>
</ul>

]]></content>
  </entry>
  
</feed>
